<html>
<body>
<div class="article-parents">
<ul class="article-journal-name">
<li>Journal of Advances in Information Fusion (JAIF)</li>
<li>Volume 3</li>
<li>Issue 1</li>
<li>Pages 3 - 13</li>
<li>June, 2008</li>
<li class="article-doi"><a href="https://doi.org/">https://doi.org/</a></li>
</ul>
</div>

<div class="article-header">
<h1 class="article-title">Optimal Policies for a Class of Restless Multiarmed Bandit Scheduling Problems with Applications to Sensor Management</h1>
<p class="article-authors">R.  Washburn and M.  Schneider</p>
</div>

<div class="article-url">
<a href="https://confcats_isif.s3.amazonaws.com/web-files/journals/entries/2-6075D01.pdf">Read Article</a>
</div>
<div id="articleBody" class="article-section">
<h2 class="article-heading" id="Abstract">Abstract</h2>
<p>   We present verifiable sufficient conditions for determining opti-    mal policies for finite horizon, discrete time Markov decision prob-    lems (MDPs) with terminal reward. In particular, a control policy    is optimal for the MDP if (i) it is optimal at the terminal time,    (ii) immediate decisions can be deferred to future times, and (iii)    the probability transition functions are commutative with respect    to different decisions. The result applies to a class of finite horizon    restless multiarmed bandit problems that arise in sensor manage-    ment applications, which we illustrate with a pair of examples.    Manuscript received January 26, 2006; revised February 25, 2008;  released for publication May 2, 2008.    Refereeing of this contribution was handled by Chee Chong.    This material is based upon work supported by the United States Air  Force under Contract No. F33615-02-C-1197.    Authors’ addresses: R. B. Washburn, Parietal Systems Inc., 510  Turnpike Street, Suite 201, North Andover, MA 01845, robert.  washburn@parietal-systems.com; M. K. Schneider, BAE Systems,  6 New England Executive Park, Burlington, MA 01803, michael.k.  schneider@baesystems.com.    1557-6418/08/$17.00 c° 2008 JAIF   </p>
</div>
<div class="references">
<h2>References</h2>
<ul class="unstructured-references">
<li class="ref-1">D. A. Berry and B. Fristedt Bandit Problems: Sequential Allocation of Experiments. Chapman and Hall, 1985.</li>
<li class="ref-2">Dynamic Programming and Optimal Control. Athena Scientific, Belmont, MA, 2001.</li>
<li class="ref-3">Optimal search strategies in dynamic hypothesis testing. IEEE Transactions on Systems, Man, and Cybernetics, 25, 7 (1995), 1130—1138.</li>
<li class="ref-4">Bandit processes and dynamic allocation indices. Journal of the Royal Statistical Society: Series B (Method- ological), 41, 2 (1979), 148—177.</li>
<li class="ref-5">Optimal policy for scheduling of Gauss-Markov systems. In Proceedings of the International Conference on Informa- tion Fusion, 2004.</li>
<li class="ref-6">Feedback control applied to survivability: A host-based autonomic defense system. IEEE Transactions on Reliability, 53, 1 (2004), 148—166.</li>
<li class="ref-7">Algorithms for optimal scheduling and management of hidden Markov model sensors. IEEE Transactions on Signal Processing, 50, 6 (2002), 1382—1397.</li>
<li class="ref-8">Hidden Markov model multiarm bandits: A methodology for beam scheduling in multitarget tracking. IEEE Transactions on Signal Processing, 49, 12 (2001), 2893—2908.</li>
<li class="ref-9">Chasing the elusive sensor manager. In Proceedings of the IEEE National Aerospace and Elec- tronics Conference, vol. 1, 1994, 606—613.</li>
<li class="ref-10">The sensor management imperative. In Yaakov Bar-Shalom (Ed.),Multitarget-Multisensor Track- ing: Applications and Advances, vol. 2, Artech House, 1992, 325—392.</li>
<li class="ref-11">Closing the loop in sensor fusion systems: Stochastic dy- namic programming approaches. In Proceedings of the American Control Conference, 2004.</li>
<li class="ref-12">Washburn Approximation methods for Markov decision problems in sensor management. BAE Systems, Burlington, MA, Technical Report TR-1620, 2005.</li>
<li class="ref-13">Stochastic dynamic programming based approaches to sen- sor resource management. In Proceedings of 5th Iternational Conference on Information Fusion, 2002, 608—615.</li>
<li class="ref-14">On an index policy for restless bandits. Journal of Applied Probability, 27 (1990), 637—648.</li>
<li class="ref-15">Restless bandits: Activity allocation in a changing world. Journal of Applied Probability, 25A (1988), 287—298. 12 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 3, NO. 1 JUNE 2008 Robert B. Washburn received his B.S. in 1973 from Yale University in mathematics and his Ph.D. in 1979 from the Massachusetts Institute of Technology in applied mathematics. He has been a principal scientist at Parietal-Systems, Inc. (PSI) since January 2006. At PSI he is developing algorithms for constraint-based data association, sensor resource management, and pattern recognition for information fusion appli- cations. Before joining PSI, Dr. Washburn worked at ALPHATECH for 23 years, where he was a Chief Scientist and during which time he led research and devel- opment in several areas of information fusion and sensor management. His work included the development of multiple hypothesis tracking (MHT) and correlation algorithms for several applications, and development and application of multi- resolution statistical image fusion algorithms and performance estimation theory for model-based target recognition algorithms. He led the efforts on sensor resource management, using approximate dynamic programming approaches to develop effi- cient control algorithms for pointing sensors and selecting sensor modes for sensing multiple targets. Dr. Washburn is a member of the IEEE, American Mathematical Society, and Society for Industrial and Applied Mathematics. Michael K. Schneider received his B.S.E. degree in electrical engineering and Certificate in applied and computational mathematics (Summa Cum Laude) from Princeton University in 1994, and his M.S. and Ph.D. degrees in electrical engineer- ing and computer science from the Massachusetts Institute of Technology in 1996 and 2001, respectively. He is a lead research engineer at BAE Systems Advanced Information Technolo- gies (BAE AIT) where, since 2001, he has been working on problems in information fusion. At BAE AIT, he has been developing combinatorial optimization algorithms for sensor resource management as well as algorithms for signature-aided tracking and analysis of patterns in historical track data. He is a member of IEEE, SIAM, and INFORMS. WASHBURN & SCHNEIDER: OPTIMAL POLICIES 13</li>
</ul>
</div>

</body>
</html>