<html>
<body>
<div class="article-parents">
<ul class="article-journal-name">
<li>Journal of Advances in Information Fusion (JAIF)</li>
<li>Volume 14</li>
<li>Issue 1</li>
<li>Pages 66 - 85</li>
<li>June, 2019</li>
<li class="article-doi"><a href="https://doi.org/">https://doi.org/</a></li>
</ul>
</div>

<div class="article-header">
<h1 class="article-title">Arabic Dynamic Gesture Recognition Using Classifier Fusion</h1>
<p class="article-authors">Basma  Hisham and Alaa  Hamouda</p>
</div>

<div class="article-url">
<a href="https://confcats_isif.s3.amazonaws.com/web-files/journals/entries/03-052018-0021R2.pdf">Read Article</a>
</div>
<div id="articleBody" class="article-section">
<h2 class="article-heading" id="Abstract">Abstract</h2>
<p>   Sign language is a visual language that is the primary way used by    hearing-impaired people in order to connect and communicate with    each other and with their societies. Some studies have been conducted    on Arabic sign language (ArSL) recognition systems, but a practically    deployable system for real-time use is still a challenge.Themain objec-    tive of this paper is to develop a novel model that is able to recognize    the ArSL using Microsoft’s Kinect V2. This paper works on the dy-    namic gestures that are performed by both hands and body parts, and    introduces an effective way of capturing and detecting the hand and    skeleton joints from the depth image that is provided by Kinect. The    model used two supervised machine learning algorithms, support vec-    tor machine (SVM) andK-nearest neighbors (KNN), and then applied    Dezert–Smarandache theory (DSmT) as a fusion technique in order to    combine their results.We compared the results of the proposed model    with the Ada-Boosting technique and finally applied two most widely    usedmethods that are usedwith dynamic gesture recognition, dynamic    time warping (DTW) and hidden Markov model (HMM), to compare    their results with the previous classifier fusion. Finally, we applied the    model on ArSL dataset that is composed of 40 Arabic medical signs to    ease the communication between hearing-impaired patients and their    doctor. The accuracy of the model is improved when the classifier fu-    sion is applied compared to using each classifier separately.The overall    accuracies for SVM, KNN, DSmT fusion, and Ada-Boosting are 79%,    89%, 91.5%, and 90.2%, respectively. Also, DTW and HMM achieved    overall accuracies of 82.6% and 79.5%, respectively.   </p>
</div>
<div class="references">
<h2>References</h2>
<ul class="unstructured-references">
<li class="ref-1">R. Hoopers et al. “Analyzing variation in sign languages: Theoretical and methodological issues,” in Signed Languages:Discoveries From International Research,M.Metzger, S. Taub, A.M. Baer, and V. Dively Eds., Washington, DC: Gallaudet University Press, 2001, pp. 135–162.</li>
<li class="ref-2">“Prototype Arabic sign language recognition using multi-sensor data fusion of two Leap Motion controllers,” in Proc. 12th Int. Multi-Conf. Syst., Signals Devices, Piscataway, NJ: IEEE, 2015.</li>
<li class="ref-3">“Evaluation of the KinectTM sensor for 3-D kinematic measurement in the workplace,” Appl. Ergonom., vol. 43, no. 4, pp. 645–649, 2012.</li>
<li class="ref-4">“RGB-D datasets using Microsoft Kinect or similar sensors: A survey,” Multimedia Tools Appl., vol. 76, no. 3, pp. 4313–4355, 2017.</li>
<li class="ref-5">“American sign language recognition using Leap Motion sensor,” in Proc. 13th Int. Conf. Mach. Learn. Appl., Piscataway, NJ: IEEE, 2014.</li>
<li class="ref-6">“A system for a hand gesture-manipulated virtual reality environment,” in Proc. Annu. Conf. South Afr. Inst. Comput. Scientists Inf. Technologists, New York: ACM, 2016.</li>
<li class="ref-7">C. Neidle “Recognition of nonmanual markers in American sign language (ASL) using non-parametric adaptive 2D–3D face tracking,” in Proc. Int. Conf. Lang. Resour. Eval., 2012.</li>
<li class="ref-8">“Arabic sign language: A perspective,” J. Deaf Stud. Deaf Educ., vol. 10, no. 2, pp. 212–221, 2005.</li>
<li class="ref-9">Machine Learning in Radiation Oncology: Theory and Applications. Cham, Switzerland: Springer, 2015, pp. 57–70.</li>
<li class="ref-10">“Comparison of four SVM classifiers used with depth sensors to recognize Arabic sign language words,” Computers, vol. 6, no. 2, p. 20, 2017. ARABIC DYNAMIC GESTURE RECOGNITION USING CLASSIFIER FUSION 83</li>
<li class="ref-11">“Representation learning: A review and new perspectives,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 8, pp. 1798–1828, Aug. 2013.</li>
<li class="ref-12">“Image-based and sensor-based approaches to Arabic sign language recognition,” IEEE Trans. Human–Mach. Syst., vol. 44, no. 4, pp. 551–557, Aug. 2014.</li>
<li class="ref-13">“Monocular vision-based signer-independent Pakistani sign language recognition system using supervised learning,” Indian J. Sci. Technol., vol. 9, no. 25, pp. 1–16, 2016.</li>
<li class="ref-14">“Recognition of Arabic sign language (ArSL) using recurrent neural networks,” in Proc. 1st Int. Conf. Appl. Digit. Inf. Web Technol., Piscataway, NJ: IEEE, 2008.</li>
<li class="ref-15">“Recognition of Arabic sign language alphabet using polynomial classifiers,” EURASIP J. Adv. Signal Process., vol. 2005, no. 13, p. 507614, 2005.</li>
<li class="ref-16">“Improving gesture recognition in the Arabic sign language using texture analysis,” Appl. Artif. Intell., vol. 21, no. 1, pp. 11–33, 2007.</li>
<li class="ref-17">and K. Nakamatsu “ArSLAT:Arabic sign language alphabets translator,” in Proc. Int. Conf. Comput. Inf. Syst. Ind. Manage. Appl., Piscataway, NJ: IEEE, 2010.</li>
<li class="ref-18">“Low complexity classification system for glove-based Arabic sign language recognition,” in Proc. 19th Int. Conf. Neural Inf. Process., 2012, pp. 262–268.</li>
<li class="ref-19">“Recognition of two-handed Arabic signs using the CyberGlove,” Arabian J. Sci. Eng., vol. 38, no. 3, pp. 669–677, 2013.</li>
<li class="ref-20">“A new approach for designing a smart glove for Arabic sign language recognition system based on the statistical analysis of the sign language,” in Proc. 34th Nat. Radio Sci. Conf., Piscataway, NJ: IEEE, 2017.</li>
<li class="ref-21">“Edge-based recognizer for Arabic sign language alphabet (ArS2V-Arabic sign to voice),” in Proc. Int. Comput. Eng. Conf., Piscataway, NJ: IEEE, 2010</li>
<li class="ref-22">“Using the Hausdorff algorithm to enhance Kinect’s recognition of Arabic sign language gestures,” Int. J. Comput. Sci. Secur., vol. 7, no. 1, p. 2, 2017.</li>
<li class="ref-23">“A proposed hybrid sensor architecture for Arabic sign language recognition,” in Intelligent Systems’ 2014. Cham, Switzerland: Springer, 2015, pp. 721–730.</li>
<li class="ref-24">“Arabic sign language recognition using the Microsoft Kinect,” in Proc. 13th Int. Multi-Conf. Syst., Signals Devices, Piscataway, NJ: IEEE, 2016.</li>
<li class="ref-25">“Arabic sign language recognition based on HOG descriptor,” in Proc. 8th Int. Conf. Graph. Image Process., vol. 10225. Bellingham, WA: International Society for Optics and Photonics, 2017.</li>
<li class="ref-26">“Arabic sign language recognition using multi-sensor data fusion,” U.S. Patent 9 672 418, Jun. 6, 2017.</li>
<li class="ref-27">“A framework for the integration of gesture and posture recognition using HMM and SVM,” in Proc. IEEE Int. Conf. Intell. Comput. Intell. Syst., vol. 4. Piscataway, NJ: IEEE, 2009.</li>
<li class="ref-28">“A Kinect based gesture recognition algorithm using GMM and HMM,” in Proc. 6th Int. Conf. Biomed. Eng. Inform., Piscataway, NJ: IEEE, 2013.</li>
<li class="ref-29">“A video based Indian sign language recognition system (INSLR) using wavelet transform and fuzzy logic,” Int. J. Eng. Technol., vol. 4, no. 5, p. 537, 2012.</li>
<li class="ref-30">“Multi-sensor data fusion for hand tracking using Kinect and Leap Motion,” in Proc. Virtual Reality Int. Conf., New York: ACM, 2014.</li>
<li class="ref-31">“Hand gesture recognition with jointly calibrated Leap Motion and depth sensor,” Multimedia Tools Appl., vol. 75, no. 22, pp. 14991–15015, 2016.</li>
<li class="ref-32">“Live demonstration: A HMM-based real-time sign language recognition system with multiple depth sensors,” in Proc. IEEE Int. Symp. Circuits Syst., Piscataway, NJ: IEEE, 2015.</li>
<li class="ref-33">“Chinese sign language recognition based on an optimized tree-structure framework,” IEEE J. Biomed.Health Inform., vol. 21, no. 4, pp. 994–1004, 2017.</li>
<li class="ref-34">“Coupled HMM-based multi-sensor data fusion for sign language recognition,” Pattern Recognit. Lett., vol. 86, pp. 1–8, 2017.</li>
<li class="ref-35">“Gesture recognition based on Kinect and sEMG signal fusion,” Mobile Netw. Appl., vol. 23, no. 4, pp. 797–805, 2018.</li>
<li class="ref-36">Character Recognition Systems: A Guide for Students and Practitioners. Hoboken, NJ:Wiley, 2007.</li>
<li class="ref-37">“Fingers and gesture recognition with Kinect v2 sensor,” Inf. Technol. Control, vol. 14, no. 3, pp. 24–30, 2016.</li>
<li class="ref-38">Advances and Applications of DSmT for Information Fusion, Collected Works, vol. 3. Rehoboth, DE: American Research Press, 2009, 760 pp.</li>
<li class="ref-39">“Efficient combination rule of Dezert–Smarandache theory,” J. Syst. Eng. Electron., vol. 19, no. 6, pp. 1139–1144, 2008.</li>
<li class="ref-40">“Probability-based dynamic time warping for gesture recognition on RGB-D data,” in Advances in Depth Image Analysis and Applications. Berlin, Germany: Springer, 2013, pp. 126–135. 84 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 14, NO. 1 JUNE 2019</li>
<li class="ref-41">“Gesture recognition: A survey,” IEEE Trans. Syst., Man, Cybern., Part C: Appl. Rev., vol. 37, no. 3, pp. 311–324, 2007.</li>
<li class="ref-42">“Albanian sign language (AlbSL) number recognition from both hand’s gestures acquired by Kinect sensors,” Int. J. Adv. Comput. Sci. Appl., vol. 7, no. 7, pp. 777–780, 2016.</li>
</ul>
</div>

</body>
</html>