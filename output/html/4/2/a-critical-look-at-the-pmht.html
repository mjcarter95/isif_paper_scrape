<html>
<body>
<div class="article-parents">
<ul class="article-journal-name">
<li>Journal of Advances in Information Fusion (JAIF)</li>
<li>Volume 4</li>
<li>Issue 2</li>
<li>Pages 93 - 116</li>
<li>December, 2009</li>
<li class="article-doi"><a href="https://doi.org/">https://doi.org/</a></li>
</ul>
</div>

<div class="article-header">
<h1 class="article-title">A Critical Look at the PMHT</h1>
<p class="article-authors">David F. Crouse, Marco  Guerriero and Peter  Willett</p>
</div>

<div class="article-url">
<a href="https://confcats_isif.s3.amazonaws.com/web-files/journals/entries/JAIF_article_Criticallook.pdf">Read Article</a>
</div>
<div id="articleBody" class="article-section">
<h2 class="article-heading" id="Abstract">Abstract</h2>
<p>   We combine concepts from numerous papers to provide a deriva-    tion and description of a generalized Probabilistic Multi-Hypothesis    Tracker that can track multiple targets in a cluttered environment,    utilizing multiple sensors and feature measurements, if available.    Additionally, we provide a full derivation of the algorithm, includ-    ing parts omitted or abbreviated in other work. We also provide an    improved analytic solution for the prior target-measurement prob-    abilities conditioned on the number of observations, a simplified    method of performing the maximization step of the algorithm when    multiple sensors are used, a consistent covariance approximation    of the algorithm when using multiple sensors, explore the use of    deterministic annealing to improve performance, and discuss im-    plementation difficulties.    Manuscript received November 11, 2008; revised April 3, 2009; re-  leased for publication April 8, 2009.    Refereeing of this contribution was handled by Yvo Boers.    This research was supported by the Office of Naval Research under  contract N00014-07-1-0429, and by Vectraxx, Inc.    We would like to thank Yaakov Bar-Shalom for his comments.    Authors’ address: Department of Electrical and Computer Engi-  neering, University of Connecticut, 371 Fairfield Way, U-2157,  Storrs, Connecticut 06269, E-mail: (fcrouse, marco.guerriero, wil-  lettg@engr.uconn.edu).    1557-6418/09/$17.00 c° 2009 JAIF    1. OVERVIEW    Since its creation by Streit and Luginbuhl in 1993  [60], much research has been done on the Probabilis-  tic Multi-Hypothesis Tracker (PMHT). In this paper,  we combine concepts from past works and provide a  general version of the PMHT algorithm allowing for  tracking in the presence of clutter (false alarms) and  missed detections and the utilization of classification  data, range rate information, and multiple synchronous  sensors. This version makes no changes to the basis of  the original algorithm, which is the Expectation Maxi-  mization (EM) algorithm. As a result, this generalized  PMHT algorithm may be used as an improved foun-  dation for other versions of the PMHT that build upon  or alter the basis of the algorithm, such as the Multi-  Frame Assignment PMHT (MFPMHT) accounting for  missed detections by Blanding, Willett, Streit, and Dun-  ham [7]. Being a generalized version of the PMHT, the  algorithm might be interchangeably named the PMHT  or the Multi-Sensor PMHT (MSPMHT), in line with the  naming convention of previous work.  In the subsequent sections, we derive the general    form of the PMHT algorithm while discussing imple-  mentation difficulties. In Section 2, an overview of pre-  vious contributions to the algorithm is provided. Sec-  tion 3 describes the EM algorithm, which forms the ba-  sis of the PMHT. Section 4 derives the state estimates  within the PMHT, discussing implementation issues as-  sociated with precision problems in 4.3, how and why  one might wish to include deterministic annealing to  improve performance in 4.3, what to do if each sen-  sor has a different field of view in 4.4, and out-of-  order measurement delivery in 4.5. In Section 5, we  compare the complexity of the PMHT against that of  the Joint Probability Data Association Filter (JPDAF),  which is a popular non-batch tracking algorithm.1 We  describe the conditions under which the PMHT has a  lower complexity than the MSJPDAF. Section 6 ex-  plains how the PMHT, a batch algorithm, can be used  over data sequences longer than the batch. Section 7  then discusses state covariance estimation in the PMHT.  The algorithm is summarized in Section 8. Section 9  provides a simulation of the PMHT with multiple sen-  sors to verify that the covariance estimation procedure  of Section 7 provides, under certain conditions, con-  sistent estimates when multiple targets are used, and  demonstrates that deterministic annealing can signifi-  cantly improve tracker performance when using multi-  ple sensors. Section 10 summarizes the paper. The ap-  pendices provide derivations of the target-measurement  association probabilities conditioned on the observa-  tions, and the target-measurement association proba-  bilities conditioned only on the number of observa-  tions.    1It is also referred to as the Multi-Sensor JPDAF (MSJPDAF) in the  multisensor case.    JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009 93        2. PREVIOUS WORK ON THE PMHT ALGORITHM    The Probabilistic Multi-Hypothesis Tracker (PMHT)  is a linear-complexity, EM algorithm based, batch target  tracking algorithm for use in tracking multiple targets  in the presence of clutter when the target-measurement  associations are unknown.2 Having a memory of the  last N scans of data, it attempts to find the maximum a  posteriori estimate of the target state in the current scan.  This is similar to a later algorithm by Pulford and Logo-  thetis [50], which estimates the target-measurement as-  sociations under different measurement models. Being  a batch algorithm, it can easily handle delayed measure-  ments, which may simply be added to the batch when  they arrive, as was mentioned by Efe, Ruan and Willett  [19]. For use as a practical tracker, which must produce  track estimates before receiving a full N scans of data,  the PMHT can be run at each step on a growing window  until a full N scans of data have been acquired, at which  point the window slides. This growing and sliding win-  dow has been shown to be more effective than other  methods by Willett, Ruan, and Streit [70].  The first EM based tracking algorithm was a max-    imum-likelihood (ML) batch algorithm by Avitzour [2].  This tracker had a high complexity, requiring the calcu-  lation of all target-measurement association probabili-  ties. A later algorithm by Molnar and Modestino [41]  was a non-batch EM approach to tracking that calculates  the maximum a posteriori (MAP) estimate and uses a  Markov random field to model the target-measurement  associations, resulting in a significantly lower complex-  ity. Jeong and Park [31] used an alternative version of  the EM algorithm to produce a recursive MAP target  tracker that also estimates various parameters, reducing  its complexity by approximating the joint association  event probabilities reducing its complexity by approxi-  mating multiple target joint association event probabil-  ities as products of single target joint association event  probabilities. Pulford and La Scala [49] used the EM al-  gorithm coupled with the Viterbi algorithm to estimate  target maneuvers.  In contrast, the PMHT uses an arguably incorrect    measurement model in order to reduce its complexity.  That is, when told that a particular measurement origi-  nated from a particular target, it ignores any condition-  ing this may imply when determining the posterior as-  sociation probabilities of the other measurements. As a  result, the probability of a particular measurement com-  ing from a particular target is independent of whether  that or any other target produced any of the other mea-  surements, and each target is allowed to produce any  number of measurements. However, each measurement  can only originate from a single target, which is realis-  tic when the targets are well resolved. A version of the  PMHT accounting for unresolved targets has also been  developed by Davey [11].    2A though the focus is on target tracking, the PMHT algorithm has  found use in other applications, such as cartography [10].    It should be noted that the PMHT is not the only  algorithm utilizing an “incorrect” measurement model.  Particle filter based trackers by Hue, Le Cadre, and  Pérez [27], [28] as well as by Gilholm, Godsill, Maskell,  and Salmond [25] utilize the same model. The mea-  surement model has some appeal when high resolution  sensors are able to over-resolve the target.  The PMHT was first proposed by Streit and Lugin-    buhl in 1993 [60] with the first full statement of the  algorithm appearing in a Naval technical report two  years later [61]. The PMHT algorithm was defined  very generally in [61], allowing for the target dynamics  and measurement model to have arbitrary distributions.  However, such a generic model did not allow for the  maximization step of the EM algorithm, upon which  it is based, to be easily performed, and thus the prac-  tical implementation presented had a discrete-time lin-  ear motion model, as used in the Kalman filter. Since  then, quite a few variants of the PMHT algorithm have  emerged, many of which have been compared by Wil-  lett, Ruan, and Streit in [71].  The best performing variants of the PMHT, that    is those having better track-loss characteristics than  the JPDAF, are the Turbo PMHT, by Ruan and Wil-  lett [56] and Willett, Ruan, and Streit [69] and Multi-  Frame PMHT (MFPMHT) algorithms. The currently  best-performing version of the PMHT is the MFPMHT  that accounts for missed detections, by Blanding, Wil-  lett, Streit, and Dunham [7], which is a modification of  an earlier MFPMHT by Streit [59]. However, the better  performance of the MFPMHTs comes with an increased  complexity, being roughly exponentially complex over  the last L frames of an N frame batch.  The homeothetic PMHT, first derived by Rago, Wil-    lett, and Streit in [53], was an ad-hoc approach to im-  proving the performance of the PMHT through the use  of multiple measurement models with different noise  covariances. The different covariances were intended to  overcome estimation problems in the PMHT and not to  function as multiple models for states inherent to the  targets. However, this may be thought of as a forerun-  ner to multiple model PMHT algorithms. Logothetis,  Krishnamurthy, and Holst [35]3 were the first to develop  a form of the PMHT algorithm involving multiple mod-  els to account for target maneuvers. The transition be-  tween model states was governed by a Hidden Markov  Model (HMM). The maneuvers were handled using ad-  ditional unknown “control” inputs to the Kalman filter.  Willett, Ruan, and Streit [69] also did this, modeling the  maneuvers as increases in the process noise of the tar-  gets forming the MPMHT. In both approaches, the ac-  tive model of the target was modeled as one of the “nui-  sance” variables in the EM algorithm. Pulford and La  Scala [49] took a different approach, making the maneu-  vers part of the quantity to be estimated in the EM algo-  rithm. Their maneuver-estimation approach can be used    3This is the journal version of an earlier conference paper [34].    94 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        with various EM-algorithm based trackers including the  PMHT. Willett, Ruan, and Streit created an interactive  multiple model approach to tracking using the PMHT  in the presence of maneuvers (IMM-PMHT), replacing  the backward-forward algorithm used in [69] with an  interacting multiple model (IMM). They also derived  a turbo-coding based extension to the MPMHT, which  they dubbed the Turbo MPMHT. This later matured into  the Turbo PMHT, as described by Ruan and Willett  [56]. More recently, Luginbuhl, Ainsleigh, Mathews,  and Streit [36] demonstrated how to derive the observed  data likelihood function for the family of manoeuvring  PMHT trackers.  The basic PMHT is an algorithm that tracks targets    based upon discrete observations at each scan. How-  ever, a variant called the Histogram PMHT (H-PMHT)  allows the PMHT to process continuous data directly  from a sensor. The concept was first introduced by Lug-  inbuhl and Willett [37] as a method of tracking a general  frequency-modulated signal in noise (explained in more  detail in [38]), and a variant appeared in [58]. Walsh,  Graham, Streit, Luginbuhl, and Mathews [64] later pre-  sented a one-dimensional application of the algorithm.  Pakfiliz and Efe [44] presented a two-dimensional ap-  plication, and most recently, Davey, Rutten, and Cheung  [15] compared it against other track-before-detect meth-  ods. In this paper, we do not consider the processing of  continuous sensor measurements. The use of the PMHT  in tracking problems with bearing-only measurements  has been studied by Giannopoulos, Streit, and Swaszek  [23].  In its original version, the PMHT did not account    for clutter. Rago, Willett, and Streit [52] extended the  PMHT to cluttered environments under a number of as-  sumptions, regarding the probability of a measurement  originating from clutter, by modifying the target mea-  surement assignment probabilities wkr(t),l(t). In the next  year, Hutchins and Dunham produced a similar version  of the PMHT for use in cluttered environments [29], in-  volving an ad-hoc constant in the denominator of the tar-  get measurement assignment probabilities. In later pub-  lications, an analytically derived solution has been used,  but no complete derivation has been given. In this paper,  we provide an explicit derivation of the PMHT includ-  ing clutter, and we provide a full Bayesian derivation of  the prior and posterior association probabilities ¼kr(t)(nt)  and wkr(t),l(t). The probabilities ¼kr(t)(nt) have previously  been derived by Wieneke and Koch [66], but here it  is developed in such a way that the solution could be  simplified by omitting “fictitious targets” that had been  used in [66].  Davey, Gray, and Streit [14] introduced the use    of target classification measurements into the PMHT.  Namely, extra data can be used to identify the type  of each observations, e.g., whether an observation is  clutter, a plane or a missile. A more complete analysis  of this work is given in Davey’s PhD thesis [9]. In this  paper, we show how classification measurements can be  used in a multisensor environment.    The simplest approach to multisensor tracking with  the PMHT was first considered by Rago, Willett, and  Streit [51]. They pooled all of the measurements from  all of the sensors together and ran the PMHT as if all of  the measurements came from a single sensor. One can  justify this by the fact that the PMHT’s measurement  model allows for a single target to produce multiple  observations. Hempel [26] considered the robustness of  the PMHT to registration errors when the measurements  from all sensors are pooled. However, versions of the  PMHT specifically accounting for multiple sensors by  modifying the likelihood function to reflect their pres-  ence have been developed, and have been shown to im-  prove the performance of the tracker over the pooled  measurement approach. These were developed concur-  rently by Krieg and Gray [33], by Giannopoulos, Streit,  and Swaszek [24] and by Gauvrit, Le Cadre, and Jauf-  fret [22]. All of these derivations used the Levenberg-  Marquadt method (described, for example in [5]) for  performing the maximization step of the EM algorithm.  In this paper, we show that a simpler, non-iterative ap-  proach exists.  In its original form, the PMHT algorithm was meant    to track a known number of targets and lacked any no-  tion of track discovery, termination or merging. How-  ever, such tasks are necessary for a tracker to be usable  in real-world situations. Several advances have been  made in integrating track discovery and termination fea-  tures into the PMHT. A complete track management  system, in which tracks were discovered and terminated  by separate algorithms outside of the PMHT algorithm,  was first introduced by Luginbuhl, Sun, and Willett  [39], whereby track extraction was done via the Hough  transform. Alexiev [1] also considered the use of the  Hough transform with the PMHT. Davey and Gray [12]  later gave a comparison of various methods of track ini-  tiation, and Dunham and Hutchins [17] considered us-  ing the MHT as a track-finding front-end to the PMHT,  whereby once tracks were stable they were handed off  to the PMHT. Since then, however, additional methods  of track management have emerged. Davey and Gray  introduced the Hysteresis PMHT [13], which treats the  existence of a target as an extra state in the estima-  tor. Mu²sicki and Wang [43] used an ad-hoc approach  of modifying the posterior association probabilities to  do the same thing. Wieneke and Willett [68] looked at  methods of determining track deletion and Wieneke and  Koch looked at hypothesis tests for estimating the num-  ber of tracks present [67].    3. THE EXPECTATION MAXIMIZATION ALGORITHM  AND DETERMINISTIC ANNEALING    The PMHT is based on the EM algorithm. The EM  algorithm, discovered by Dempster, Laird, and Rubin  [16], is a method of determining the ML or MAP es-  timate of data given incomplete information. Redner  and Walker [54] specifically looked at the use of the    A CRITICAL LOOK AT THE PMHT 95        EM algorithm for ML estimation of parameters of mix-  ture densities, a topic that is relevant to EM algorithm  based target tracking. The EM algorithm is summarized  here, which is extensively covered in the monograph  by McLachlan and Krishnen [40], and we must note  the tutorial by Moon in [42]. It should be noted that  the EM algorithm does not provide the covariance of  its estimate. This is, however, necessary for the tracker  to be useful and is discussed in Section 7.  Let X be an unknown random quantity the MAP    estimate of which we would like to find. Let Z be  the set of observations, which are dependent upon X  and a set of unobservable random variables K. We  would like to find the MAP estimate of X without  having to determine K, which might be a difficult or  computationally complex task. The MAP estimate of X  may be expressed as    X̂MAP = argmax  X  Eflog(p(X j Z))g, (1)    in which p represents a probability density function  (PDF). The expectation comes from the Law of Total  Probability eliminating the unobservable random vari-  able K. However, in many cases the expectation may  be difficult to evaluate. The EM algorithm avoids direct  computation of this expectation. Define the following  function:    Q(X(n+1);X(n))    ¢  =  Z  K  log(p(X(n+1),K j Z))p(K jX(n),Z)dK: (2)    The integration in (2) is defined over whichever measure  is appropriate for K, which may be discrete. The EM  algorithm is as follows: in each step, X(n+1) is found as    X(n+1) = argmax  X(n+1)    Q(X(n+1);X(n)): (3)    n is then incremented and one continues until a desired  level of convergence has been attained.  In some instances, the PDF p(X(n+1),K j Z) may be    difficult to determine. If this is the case, by the definition  of conditional expectation, it can be noted that    p(X,K j Z) = p(Z,X,K)  p(Z)    : (4)    Substituting (4) into (2) and separating the logarithm  we get    Q(X(n+1);X(n))    =  Z  K  log(p(Z,X(n+1),K))p(K jX(n),Z)dK¡ logp(Z):    (5)    Because p(Z) is a constant, that term may be dropped  from (5), since it has no effect on the location of the  maximum and thus p(X(n+1),K j Z) and p(Z,X(n+1),K)  may be used interchangeably in the EM algorithm.  Boyles [8] and Wu [30] studied the convergence    properties of the EM algorithm, correcting a mistake    in Theorem 2 of Dempster, Laird, and Rubin’s origi-  nal paper [16]. They showed that the EM algorithm is  guaranteed to converge to a saddle point or a local max-  imum, which need not be the desired global maximum.  To which critical point it converges is highly dependent  upon the initial estimate X(1).  Over the years, a number of versions of the EM algo-    rithm have been developed, many of which are summa-  rized by McLachlan and Krishnen [40] and by Roche  [55]. Most sought to increase the convergence speed  of the algorithm. However, for the PMHT algorithm,  the primary concern is avoiding convergence to local  maxima. In order to reduce dependence on the initial  estimate and encourage convergence to the global max-  imum, the Deterministic Annealing (DA) EM algorithm  was developed by Ueda and Nakano [62], who recog-  nized that solving the maximum likelihood problem is  analogous to similar problems linking concepts in ther-  modynamics and information theory. This was applied  to the PMHT first in 1999 by Strandlie and Zerubia  [57] and was later applied in a more general form by  Wieneke and Koch [66]. When tracking a single target,  the basic PMHT algorithm with deterministic anneal-  ing is identical to the Deterministic Annealing Filter by  Frühwirth and Strandlie [20]. As shall be described after  the basic derivation of the PMHT, deterministic anneal-  ing can be added to almost any version of the PMHT  algorithm. To derive the DA-EM algorithm, we shall use  the definition of conditional expectation to note that    p(K jX(n),Z) = p(Z,K,X  (n))R    K1  p(Z,K1,X    (n))dK1  : (6)    The denominator in (6) is equal to p(Z,X). The DA-EM  algorithm substitutes (6) into (2) and introduces the term  ¯ as    QDA(X  (n+1);X(n))    ¢  =    Z  K    log(p(X(n+1),K j Z)) p(Z,K,X  (n))¯R    K1  p(Z,K1,X    (n))¯dK1  dK:    (7)    In the original description of the DA-EM algorithm, ¯,  the inverse of which corresponds to the “temperature”  in an analogous thermodynamic problem, is initially set  to a value between 0 and 1. QDA is then iterated with  respect to X(n+1) and X(n) until convergence, as is done  in the regular EM algorithm. Then ¯ is increased to  a value closer to one and QDA is again iterated until  convergence. The DA-EM algorithm is complete when  ¯ has finally been increased to 1. Note however, that  the original version of the DA-EM algorithm did not  specify exactly how ¯ was to be increased.  When ¯ < 1, the PDF p(K jX(n),Z) becomes flat-    ter, which reduces dependence of the algorithm on X(n).  The reasoning behind the DA-EM algorithm is that by  slowly increasing ¯, the effect of p(K jX(n),Z) is in-  creased at the same time that the estimate X(n) improves.    96 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        In the final step ¯ = 1 and (7) is equivalent to (2) and  the EM algorithm should be more likely to converge to  the global MAP estimate, because of the improved prior  estimate X(n).  In order to use the DA-EM algorithm in a practical    implementation, one must have a method of increasing  ¯. If ¯ is increased very slowly, then in general, one  iteration should be enough for convergence at each  value of ¯. Thus, in [57] and [66], the DA-EM algorithm  was carried out as follows:    Let nmax be the number of iterations that one  wishes to do. For each iteration from n= 1 on-  wards, set ¯ = n=nmax. Now iterate the EM algo-  rithm as would normally be done. That is, Xn+1 is  the set to the value maximizing QDA(X    (n+1);X(n))  at each step. In the final iteration ¯ = 1 and the  result is the EM algorithm result.    Although convergence to the global MAP estimate is  not guaranteed, as long as nmax is large enough, this  approach will generally outperform the basic EM algo-  rithm. In Section 9, we demonstrate how deterministic  annealing improves tracking performance when multi-  ple sensors are used. Although the above method is the  procedure needed to get the MAP estimate, the ML es-  timate can be attained by replacing p(X(n+1),K j Z) with  p(Z,K jX(n+1)).    4. THE PMHT ALGORITHM: STATE ESTIMATES    We shall now derive a general form of the PMHT  algorithm allowing for the presence of clutter, multiple  synchronous sensors and the use of classification infor-  mation. The most general form of the PMHT allows for  a very generic target motion and measurement model  [61]. However, due to the difficulty of the maximiza-  tion step of the EM algorithm under a generic model,  practical implementations of the PMHT are often based  upon the motion models that, in the absence of target-  measurement association uncertainty, contain the as-  sumptions inherent to the basic Kalman filter (see, e.g.,  [4]). We shall derive the PMHT under such a model,  accounting for clutter, taking advantage of multiple sen-  sors, and utilizing classification data. It shall be assumed  that the measurement noise between sensors is uncorre-  lated and that sensors have the same field of view. The  case where the sensors have different fields of view and  gating is present, is discussed in the following section.  Given M targets, the state vector at time t for the    mth target shall be designated as xm. The observation  originating from the mth target shall be designated  ym(t). The basic discrete-time kinematic motion and  observations equations are given by4    xm(t+1) = Fm(t)xm(t) + vm(t) (8)    4The Kalman filter and Kalman smoother equations associated with  this model are summarized in Appendix D.    and  ym(t) =Hm(t)xm(t) +wm(t): (9)    The process noise at time t, vm(t), is assumed to be  Gaussian distributed with zero mean and covariance  Qm(t). The measurement noise wm(t) is also modeled as  a zero-mean Gaussian random variable with covariance  Rm(t) and is assumed to be uncorrelated with the process  noise. The covariance of the true measurement from the  mth target Rm(t) describing wm(t) from (9), corresponds  to the covariance of one of the measurements out of the  set of all measurements at time t, whereby Rr,s(t) shall  represent the covariance of measurement r from sensor  s based upon the location of the observation, without  stating a particular associated target.  Let Z be all of the measurements and classification    information from time t= 1 to N. Let X be the states of  all of the targets over the same time period and K be the  set of associations between targets and measurements.  Let there be a total of S sensors that take measurements  synchronously. If zr,s(t) is the measurement r at time  t from sensor s that came from target m, then we  shall denote said association by kr,s(t) =m. We would  like to use the EM algorithm to estimate X without  explicitly determining which set of kr,s(t) from the set  of all possible target to measurement associations, K, is  correct. We shall consider clutter to be target m= 0.  The inclusion of classification measurements in the    PMHT was first discussed by Davey, Gray, and Streit  [14]. We shall assume that some type of classification  has already been done for each measurement, giving us  zCr,s(t), the classification data associated with measure-  ment r from sensor s at time t. Including classification  in the PMHT means estimating the type of each target.  This is done via a confusion matrix C whose elements  are defined as    c(i,m) = Pr(zCr,s(t) = i j kr,s(t) =m): (10)  i in (10) represents the ith classification out of the set  of allMC possible classifications. The true classification  of each target is assumed to be time-invariant, which  is why ci,m is not indexed against time.    5 That is, the  appearance of each target is assumed to be constant. It  shall also be assumed independent of that state. The  confusion matrix is the estimated probability that a  target or a clutter measurement has a certain associated  appearance. The confusion matrix shall be estimated  along with X in the PMHT algorithm. Thus, argmaxi ci,m  will be the MAP estimate of the classification of target  m at the end of the algorithm.  Let us find the first PDF in (5), including C next    to X as an unknown to be estimated. Let nt(s) be the  number of measurements at time t that came from    5This assumption plays a role in our subsequent estimation of the  confusion matrix via the EM algorithm as part of the PMHT. However,  if one does not wish to perform EM algorithmic estimation of the  confusion matrix, then a time-varying confusion matrix may be used  without modification to the rest of the PMHT.    A CRITICAL LOOK AT THE PMHT 97        sensor s. In order for p(Z,X,K,C) to be written, it  shall be conditioned on nt(s). However, we will not  explicitly write this conditioning except when necessary.  p(Z,X,K,C) is given as    p(Z,X,K,C)    = p(X)p(Z,K,C jX) (11a)    =    p(X)z }| {Ã  MY  m=1    p(x  m  (1))    NY  tx=2    p(x  m  (t  x  ) j x    m  (t  x  ¡ 1))    !    £    p(Z,KjX)z }| {  SY  s=1    NY  t=1    nt(s)Y  r=1    Pr(k  r,s(t) j xkr,s(t)(t),nt)p(zr,s(t) j kr,s(t),xkr,s(t)(t))    £  p(CjZ,X,K)z }| {    c(zC  r,s(t),kr,s(t)) : (11b)    In (11b), the PDF p(zr,s(t) j kr,s(t),xkr,s(t)(t)) depends  upon whether the measurement came from clutter or  from a target and is given by    p(zr,s(t) j kr,s(t),xkr,s(t)(t))    =    (  ¹(t,zr,s(t)) if kr,s(t) = 0    Nfzr,s(t); ŷkr,s(t)(t),Rr,s(t)g if kr,s(t) 6= 0  :    (12)    In (12), ¹ denoted the PDF of the clutter, which we shall  assume to be continuous as a function of zr,s(t), and  which need not be uniform, and ŷkr,s(t)(t) is the estimate  of y from (9). That is,    ŷkr,s(t)(t) =Hkr,s(t)(t)xkr,s(t)(t): (13)    Define wkr,s(t),r(t,s)  ¢  =Pr(kr,s(t) j xkr,s(t)(t),Z(t),C,nt(s)) as    the probability of a particular measurement-target as-  signment at time t, whereby clutter is target kr,s(t) = 0.  We shall refer to these as the “posterior association  probabilities.” One instance of K defines kr,s(t) over all    measurements r and sensors s, for all time in the batch.  The sum over K is equal to the sum over all sensors of  the sum over Ks, which is defined as    X  Ks    (¢) =  MX    k1,s(1)=0    MX  k2,s(1)=0    ¢ ¢ ¢  MX    kn1(s),s(1)=0    MX  k1,s(2)=0    ¢ ¢ ¢  MX    knN (s),s(N)=0    (¢):    (14)    Under the basic PMHT assumption, because each tar-  get can produce more than one measurement, all of the  values of wkr,s(t),r(t,s) at a particular time are indepen-  dent. Additionally, because the current state and obser-  vation set are given, the values of wkr,s(t),r(t,s) are also  independent as a function of time. Because of this in-  dependence, p(K jX,C,Z), the second PDF in (5), may  be obtained directly by multiplying the marginal prob-  abilities over all time and measurements for all of the  assignments:    p(K jX,C,Z) =  SY  s=1    NY  t=1    nt(s)Y  r=1    wkr,s(t),r(t,s): (15)    In order to make the notation in the above equation  correct if there are no observations at a particular sensor  at a certain time, that is if nt(s) = 0, the following  definition must be used:    0Y  r=1    wkr,s(t),r(t,s)  ¢  =1: (16)    We would now like to determine the posterior  association probability wkr,s(t),r(t,s). In previous pub-  lished works on the PMHT, no formal derivation of  this in the presence of clutter has been done and be-  cause it is not immediately obvious, it shall be in-  cluded here for completeness, in Appendix A. Define    ¼kr,s(t)(nt(s), t)  ¢  =Pr(kr,s(t) =m j xm(t),nt(s)). This shall be    referred to as a “prior association probability.”6 The  ¼kr,s(t)(nt(s), t) values were derived using “imaginary”  targets by Wieneke and Koch [66] and we have red-  erived them in a simpler form in Appendix B. The orig-  inal PMHT algorithm made them a parameter to be es-  timated by the EM algorithm.  Using the solution from Appendix A for kr,s(t) 6= 0,    that is when measurement r from sensor s is not clutter,  then the posterior association probabilities for non-  clutter targets are as follows (in the final solution to the  PMHT algorithm, it will turn out that one never needs  to evaluate w0,r(t,s)):    wkr,s(t),r(t,s) =  ¼kr,s(t)(nt(s), t)Nfzr,s(t); ŷkr,s(t)(t),Rr,s(t)gc(zCr,s(t),kr,s(t))    ¼0(nt(s), t)¹(t,zr,s(t))c(z  C  r,s(t),0)+    PM  m=1¼m(nt(s), t)Nfzr,s(t); ŷm(t),Rr,s(t)gc(zCr,s(t),m)    : (17)    In a simple model where all targets have the same  probability of detection, PD(s), when viewed by sensor  s, and the number of clutter points at each sensor    6“prior association probability” is somewhat of a misnomer, since  ¼  kr,s(t)    (n  t  (s), t) is conditioned on the number of observations. How-    ever, this naming convention helps differentiate it from the posterior  association probabilities.    98 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        is Poisson distributed with mean ¸(s)V(s) where ¸(s)  represents the mean amount of clutter per unit volume  at sensor s and V(s) is the volume of the viewing area  for that sensor, then, as derived in the Appendices B  and C, the prior association probabilities are the same  for all non-clutter targets and may be divided across  the numerator and denominator giving us the following  expression for wkr,s(t),r(t,s)    wkr,s(t),r(t,s) =  Nfzr,s(t); ŷkr,s(t)(t),Rr,s(t)gc(zCr,s(t),kr,s(t))    ¼̄s(nt(s), t)¹(t,zr,s(t))c(z  C  r,s(t),0)+    PM  m=1Nfzr,s(t); ŷm(t),Rr,s(t)gc(zCr,s(t),m)    , (18)    ¼̄s(nt(s), t) =¡M ¡  2F0    ·  ¡M,¡nt(s);    PD(s)  (1¡PD(s))¸(s)V(s)    ¸  2F0    ·  1¡M,1¡ nt(s);    PD(s)  (1¡PD(s))¸(s)V(s)    ¸ , (19)    here the function 2F0[a1,a2;z] is a hypergeometric func-  tion.  Combining (15) and (11b) and omitting the constant    p(Z) we may form the Q function for the basic EM  algorithm in (5):    Q(Xn+1,Cn+1;Xn,Cn) =  X  K    log(p(Z,X(n+1),C(n+1),K))p(K jXn,Cn,Z) (20a)    = log    0  @ MY  m=1    p(x(n+1)m (1))  NY  tx=2    p(x(n+1)m (tx) j x(n+1)m (tx¡1))  1  A    +  X  K    SX  s=1    NX  t=1    nt(s)X  r=1    log(¼kr,s(t)(nt(s), t))  SY    s1=1    NY  t1=0    nt(s1)Y  r1=1    w  (n)  kr1,s1 (t1),r1    (t1,s1)    +  X  K    SX  s=1    NX  t=1    nt(s)X  r=1    log(c(zCr,s(t),kr,s(t)))  SY    s1=1    NY  t1=0    nt(s1)Y  r1=1    w  (n)  kr1,s1 (t1),r1    (t1,s1)    +  X  K    SX  s=1    NX  t=1    nt(s)X  r=1    log(p(zr,s(t) j kr(t),x(n+1)kr,s(t) (t)))  SY    s1=1    NY  t1=0    nt(s1)Y  r1=1    w  (n)  kr1,s1 (t1),r1    (t1,s1): (20b)    The superscripts in parentheses in (20b) indicate wheth-  er the values in question are to be calculated using  the current or the previous estimate of X in the EM  algorithm. As pointed out by Davey [9] in his thesis,  (20b) is simplified by use of the two identities    X  Ks    NY  t=1    ntY  r=1    wkr,s(t),r(t,s) = 1 (21)    and X  Ksnkr1,s(ti)    NY  t=1    ntY  r=1    wkr,s(t),r(t,s) = wkr1,s(ti),r1  (ti,s): (22)    Equation (21) comes from the fact that at any given  time the observations must have originated from a target  or from clutter. Ksnkr1,s(ti) represents the set of all  assignments involving sensor s except for kr1,s(ti) and  (22) comes directly from the definition of wnkr,s(t),r(t,s).  Note that when kr,s(t) = 0, that is when observation  r is clutter, p(zr,s(t) j kr,s(t),xkr,s(t)(t)) contains no terms    involving X. Therefore, for purposes of maximizing Q,  we may omit all clutter terms from the second set of  sums, because they disappear when the derivative is  taken. Using this fact and (21) and (22), Equation (20b)  may be simplified as follows:    Q(Xn+1;Xn)    =    SX  s=1    NX  t=1    nt(s)X  r=1    MX  m=1    log(¼  m  (n  t  (s), t))w(n)    m,r(t,s)    )  Q  ¦    +    SX  s=1    NX  t=1    nt(s)X  r=1    MX  m=1    log(c(zC  r,s(t),m))w    (n)  m,r(t,s)    )  QC    +log  ³QM    m=1  p(x(n+1)    m  (1))  QN    tx=2  p(x(n+1)    m  (t  x  ) j x(n+1)    m  (t  x  ¡ 1))́    +  PS    s=1    PN  t=1    PM  m=1    Pnt(s)  r=1    £ log(Nfz  r,s(t); ŷ    (n+1)  m    (t),R  r,s(t)g)w(n)m,r(t,s)    9>=  >;QX:  (23)    A CRITICAL LOOK AT THE PMHT 99        The maximization of the state component of the Q-  function, QX, from (23), is performed indirectly by  finding an equation with the same gradient, rXn+1QX,  and thus the same inflection points. Omitting constant  terms, the derivative taken over the innermost sum may  be transformed as follows:    rx  "  nt(s)X  r=1    w(n)m,r(t,s)(zr,s(t)¡Hr,sx(n+1)(t))Rr,s(t)¡1(zr,s(t)¡Hr,sx(n+1)(t))0  #    (24a)    =  nt(s)X  r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1(zr,s(t)¡Hr,sx(n+1)(t)) (24b)    =  nt(s)X  r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1zr,s(t)¡  nt(s)X  r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1Hr,sx  (n+1)(t) (24c)    =    Ã  nt(s)X  r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1Hr,s    !    £  0  @Ãnt(s)X    r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1Hr,s    !¡1Ã  nt(s)X  r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1zr,s(t)    !  ¡ x(n+1)(t)    1  A (24d)    = R̃m,s(z̃m,s¡ x(n+1)(t)) (24e)  =rx[(z̃m,s(t)¡ x(n+1)(t))R̃m,s(t)¡1(z̃m,s(t)¡ x(n+1)(t))0]: (24f)    The synthetic measurements z̃m,s(t) and R̃m,s(t)  ¡1 are    defined by    R̃m,s(t)  ¡1 =    nt(s)X  r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1Hr,s (25)    and    z̃m,s(t) = R̃m,s(t)    Ã  nt(s)X  r=1    w(n)m,r(t,s)H  0  r,sRr,s(t)    ¡1zr,s(t)    !  :    (26)    Note that R̃m,s(t)  ¡1 may not be invertible, so a pseu-    doinverse may be necessary. The equivalency between  (24a) and (24f) means that QX from (23) has the same  derivative as    Q̂(Xn+1;Xn)    = log    Ã  MY  m=1    p(x(n+1)  m    (1))  NY  t=2    p(x(n+1)  m    (t) j x(n+1)  m    (t¡ 1))  !    ¡ 1  2    SX  s=1    NX  t=1    MX  m=1    (z̃  m,s¡ x(n+1)m (t))0    £ R̃  m,s(t)    ¡1(z̃  m,s¡ x(n+1)m (t)): (27)    Equation (27) is the joint likelihood function of M  targets for which there are observations from multiple    sensors but no data observation uncertainty. The second  term of (27) may be rewritten as follows:    ¡ 1  2    NX  t=1    MX  m=1    (z̃  m  ¡H    m  x(n+1)  m    (t))0R̃  m  (t)¡1(z̃    m  ¡H    m  x(n+1)  m    (t)):    (28)    Letting Ixm be an identity matrix whose width is equal  to the number of states in xm, z̃m(t) and R̃m(t) are given  by    z̃m(t) = [z̃m,1(t), z̃m,2(t), : : : , z̃m,S(t)], (29)    Hm = [Ixm,1, Ixm ,2, : : : ,Ixm ,S], (30)    and    R̃m(t) = diag[R̃m,1, R̃m,2, : : : ,R̃m,S]: (31)    Substituting equation (28) into (27) is equivalent to  a single-sensor system with no data association uncer-  tainty having measurements given by (29), (30), and  (31). The maximization of Q̂ is thus the maximiza-  tion of a single sensor system, the solution of which  is well known (e.g., [4]) to be the use of the Kalman  smoother (the equations for the Kalman smoother are  summarized in Appendix D). This is a simpler ap-  proach than using the Levenberg-Marquardt nonlinear  regression procedure, as suggested by Giannopoulos,  Streit, and Swaszek [24] in the original derivation of  the PMHT with multiple sensors. The use of the Kalman  smoother was also present in the original single sensor  PMHT algorithm.  This method of stacking measurements is a com-    mon method of measurement fusion for the Kalman  filter when there is no target-measurement association  uncertainty. Gan and Harris [21] showed that if at a    100 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        particular time for a particular track all sensors have the  same measurement matrix, which being Ixm ,1 is true in  this case, then the above method of merging the states  is equivalent to a simpler method. Namely, each track is  updated using a single, merged measurement given by    z̃m(t) =    Ã  SX  s=1    R̃m,s(t)  ¡1  !¡1 SX    s=1    R̃m,s(t)  ¡1z̃m,s(t)    (32)  and    R̃m(t) =    Ã  SX  s=1    R̃m,s(t)  ¡1  !¡1    : (33)    The Kalman smoother may be thought of as running  a forward Kalman filter, and then running a backwards  smoothing operation on the track estimate resulting  from the Kalman filter step. Note that the use of the  pseudoinverse in (26) may be completely avoided if  the information filter (described, for example, in [4])  is used in place of the Kalman filter in the first half of  the Kalman smoother. The information filter calls for  R̃m,s(t)    ¡1z̃m,s(t), obviating the need to invert R̃m,s(t)  ¡1 in    (26).  In general, except when range-rate information is    provided by the sensors, all Hr,s for a particular sensor  s will be the same for all measurements. In this instance,  the steps leading up to (24f) may be simplified, resulting  in the following simplified synthetic measurements    z̃  m,s(t) =    Ã  nt(s)X  r=1    w(n)  m,r(t,s)Rr,s(t)    ¡1    !¡1  nt(s)X  r=1    w(n)  m,r(t,s)Rr,s(t)    ¡1z  r,s(t)    (34)  and    R̃m,s(t) =    Ã  nt(s)X  r=1    w(n)m,r(t,s)Rr,s(t)  ¡1  !¡1    : (35)    The form of the synthetic measurements in (34) and  (35), allowing for each measurement to have a differ-  ent covariance matrix was first given in [66]. Previous  versions assumed that all measurements have the same  covariance. The forms given in (25) and (26) allow-  ing for different measurement matrices, as occurs with  doppler measurements, are unique to this paper. Note  that if each sensor has a different measurement matrix,  then the measurement fusion method given in (32) and  (33) is no longer optimal. In this case, the merged mea-  surement given in (29) and (31) should be used with the  modified merged measurement matrix,    Hm = [H1,H2, : : : ,HS] (36)    where Hs is the measurement matrix of the sth sensor.  The maximization of the confusion matrix via the    gradient rCn+1QC from (23) is performed under the  constraint    MCX  i=1    ci,m = 1: (37)    Using (23) and (37), the Lagrangian to maximize is:    LC =  SX  s=1    NX  t=1    nt(s)X  r=1    MX  m=1    log(c(zCr,s(t),m))w  (n)  m,r(t,s)    +  MX  m=1    ¸Cm    Ã  1¡    MCX  i=1    c(i,m)    !  (38a)    =  SX  s=1    NX  t=1    nt(s)X  r=1    MX  m=1    MCX  i=1    ±(zCr,s¡ i) log(c(i,m))w(n)m,r(t,s)    +  MX  m=1    ¸Cm    Ã  1¡    MCX  i=1    c(i,m)    !  : (38b)    Equation (38a) is equivalent to (38b), where ±(t) is the  Kronecker Delta function, which is one for t= 0 and  zero otherwise. Differentiating (38b) with respect to a  particular c(i,m) gives    ci,m =  1  ¸Cm    SX  s=1    NX  t=1    ntX  r=1    ±(zCr,s¡ i)w(n)m,r(t,s): (39)    Applying the constraint given in (37) gives    ¸Cm =  SX  s=1    NX  t=1    ntX  r=1    MCX  i=1    ±(zCr,s¡ i)w(n)m,r(t,s) (40a)    =  SX  s=1    NX  t=1    ntX  r=1    w(n)m,r(t,s): (40b)    Combining (39) and (40b) gives us the update for the  ci,m:    ci,m =    PS  s=1    PN  t=1    Pnt  r=1 ±(z    C  r,s¡ i)w(n)m,r(t,s)PS    s1=1    PN  t1=1    Pnt  r1=1    w  (n)  m,r1 (t1,s1)    : (41)    4.1. Regarding the Kalman Smoothing Step    The equations for the Kalman smoother are given in  Appendix D. It should be noted that although the EM  algorithm might call for the initial state estimate for each  track, xm(1), to be smoothed along with the rest, prac-  tically the algorithm is not usable in this manner. The  first part of the Kalman smoother is done by running  a Kalman filter forward on the data. This requires a  covariance estimate for the initial state. On the first iter-  ation of the EM algorithm, this is not a problem. On ad-  ditional iterations, however, we do not have a valid esti-  mate for the covariance of the smoothed initial estimate.  If one were to use the covariance estimate coming out  of the Kalman smoother, then this value would decrease  every iteration as a result of “information incest.” That  is, the initial state would repeatedly get smoothed by  using much of the same data as before, but the Kalman    A CRITICAL LOOK AT THE PMHT 101        smoother would interpret this data as being “new” and  at every iteration the covariance estimate of the initial  state would decrease. After enough iterations, the co-  variance assumed for the initial state will approach zero  even though we would not have supreme confidence in  the initial state.  A solution to this problem is to forego smoothing    the initial state at each step and to use its initial state  covariance at every iteration. That is equivalent to taking  the initial state out of the set of states X that are to be  estimated by the EM algorithm.    4.2. Precision Problems with the PMHT    Being based thereupon, all versions of the PMHT  algorithm suffer the same precision problems that can  occur with regular Kalman filter. Verhaegen discusses  the source of some of these problems as well as their  remedies [63] and such problems are also discussed  in most textbooks, such as [4]. The PMHT, however,  has a number of its own precision problems that must  be taken into account when designing any implementa-  tion.  At any step when calculating the posterior associ-    ation probabilities values for non-clutter targets, if all  valid measurements are far from the predicted value  ŷnkr(t)(t), then it is quite likely that precision limitations  will render all of the ws to be zero.7 In many such  instances, one can forego the use of the ws and as-  sume that there was a missed detection. In compari-  son with other algorithms, precision is a serious prob-  lem in the PMHT, because the non-clutter PDFs in w    are normally distributed having a covariance equal to  that of the measurement. In instances where the process  noise covariance is large and the measurement noise  covariance is small, precision errors can cause all of the  ws for a particular target to be zero much of the time.  Thus, paradoxically, the performance of the PMHT can  worsen as the magnitude of the measurement covariance  decreases. In instances where no measurement noise is  present, the PMHT is unusable.    7If a clutter model is present, then there will always be a nonzero  (clutter) term in the denominator of the ws, thus precision problems  can render all of the ws to be zero. However, if there is no clutter  term, then precision problems couples with distant measurements can  result in the fraction computed for the w to evaluate as 0/0. This can  signify that the target was not detected, or that the observation from  the target was very far from the predicted position.    4.3. Using Deterministic Annealing    The use of deterministic annealing can both help the  PMHT to converge to the global MAP estimate as well  as ameliorate precision problems associated with the  posterior association probabilities. Which maxima the  EM algorithm converges to is highly dependent on the  initial state estimates over the entire batch. Deterministic  annealing is an approach to reduce the dependence of  the algorithm on the initial estimates. However, this may  require more iterations of the EM algorithm than if  deterministic annealing were not used. As a result, just  incorporating deterministic annealing without changing  the number of iterations used could theoretically worsen  performance.  As shown in (7), the EM function with determin-    istic annealing replaces p(K jXn,Z) in the regular EM  algorithm with    p(K jXn,Cn,Z) = p(Z,K,X  n,Cn)¯P    K1  p(Z,K1,X    n,Cn)¯dK1  :    (42)    The solution for p(K jXn,Z) given in (15) is a product  of w terms. The addition of the ¯ terms in (42) to  (15) can take place without explicitly decomposing  p(K jXn,Z) into the parts listed in (42).  We note that each w term in (15) has a single    value in the numerator as well as a sum of values  in the denominator. The inclusion of the ¯s is done  by modifying the w terms as follows. For non-clutter  association probabilities, each w shall be adjusted from  (17) according to    wkr,s(t),r(t,s)    =  (¼kr,s(t)(nt(s), t)c(z    C  r,s(t),kr,s(t))Nfzr,s(t); ŷkr,s(t)(t),Rr,s(t)g)¯    (¼0(nt(s), t)¹(t,zr,s(t))c(z  C  r,s(t),0))    ¯ +  PM  m=1(¼m(nt(s), t)c(z    C  r,s(t),m)Nfzr,s(t); ŷm(t),Rr,s(t)g)¯    : (43)    Equation (43) is equivalent to raising the numerator and  each term in the denominator of (17) to the power of ¯.  The same would be done with the w for the clutter as-  signment, which we have omitted; there too one would  raise the numerator and each term of the denominator  to ¯. Once all of the w terms have been multiplied, as in  (15) the result is thus the same as (42) except all com-  mon terms have been canceled out between the numera-  tor and denominator. That is, the result is still a numera-  tor raised to ¯ and a denominator consisting of a sum of  terms each raised to ¯. This is the same as the solution  given by Wieneke and Koch [66] without derivation and  similar to what Strandlie and Zerubia [57] derived.  For precision purposes, the exponentiation of the    normal PDFs in (43) is best performed by distributing  ¯ to the terms of the normal PDF, rather than evaluat-  ing the normal PDF and then exponentiating it. Because    102 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        ¯ · 1, this increases the argument of the exponential  function of the PDF, which is where underflow prob-  lems are most likely to occur.    4.4. Sensors with Different Fields of View    The state estimate for the PMHT was derived assum-  ing that all sensors have the same field of view. When  the sensors have different fields of view, the calcula-  tion of the posterior association probabilities (the ws) is  different for each sensor.  Generally, a particular target will have a certain    probability of detection when viewed by a particular  sensor. In calculating the posterior association proba-  bilities, this detection probability is necessary for calcu-  lating the prior association probabilities. This detection  probability can be considered to be the product of the  probability that the target is located within the field of    view of the sensor times the probability that the sensor  detects the target given that it is in its field of view.  As shown in Appendix B, the computation of the    prior association probabilities (the ¼s) is combinatori-  ally complex if all of the targets have different prob-  abilities of detection. This is the case when one takes  into account the probability that each target is within  the field of view of each sensor. The complexity of this  situation may be reduced either by assuming a constant  detection probability for all targets within the field of  view of a sensor and gating to targets that should be  within the field of view given the state estimates. Once  gating has been done, this means that the prior and pos-  terior association probabilities for each sensor are calcu-  lated assuming a reduced number of targets: only those  that fall within the gate for that sensor.    4.5. Out-of-Sequence Measurements    In many practical data fusion schemes, measure-  ments may arrive at the fusion center out of sequence.  As was noted by Efe, Ruan, and Willett [18], the PMHT  handles such situations with ease. Because the PMHT is  a batch algorithm, as long as newly received measure-  ments correspond to a step that has not left the sliding  window, the measurements may be added to the batch  at any time and are used in the state update.    5. THE COMPLEXITY OF THE JPDAF VS. THE PMHT    The most complex part of the JPDAF is the evalu-  ation of the posterior association probabilities. These  are equivalent to the posterior association probabili-  ties in the single-sensor PMHT, but with slightly dif-  ferent conditioning. The evaluation of these probabili-  ties is complex, because it requires the evaluation and  normalization of the likelihoods of all possible target-  measurement assignment combinations, a task requiring  the evaluation of the exponential function for every like-  lihood.  In the worst-case scenario, every measurement at    time step t would fall in every target’s gating region. Let  nt be the number of measurements at step t and M be  the number of targets. The number of possible target-  measurement assignments may be decomposed based  upon the number of targets observed and is given as  follows:    AJPDAF =  min(nt,M)X  l=0| {z }    Sum over the number  of targets observed    μ  M    l    ¶  | {z }    Choose which targets  are observed    μ  nt  l    ¶  | {z }    Choose which measurements  are observed    l!|{z}  Assign the measurements    to the targets    (44a)    = 2F0[¡nt,¡M;1]: (44b)    2F0 refers to a generalized hypergeometric function. The  step from (44a) to (44b) was performed by noting that  the ratio of the al+1 and the alth term of the sum in (44a)  is:    al+1  al    =  (l¡nt)(l¡M)    1+ l  : (45)    More information on the conversion of sums to hyper-  geometric functions may be found in [48].  In contrast, although the PMHT allows for more pos-    terior association probabilities than the JPDAF, due to  their product form (i.e., the assumed independence of  the associations) these do not need to be enumerated  individually. The evaluation of each measurement asso-  ciation probability w requires evaluating a single normal  PDF, and in the end normalizing over all w terms and  a clutter term. Thus, the number of evaluations of the  exponential function that need be done for one iteration  at one time step in the PMHT is equal to the number  of w terms, which is ntM. Thus, if the batch length of  the PMHT is N, and I iterations are used then, noting  that the first estimate in the batch does not change with  each iteration, the overall complexity of the PMHT is:    APMHT = IM  NX  t=2    nt: (46)    As shown in Table I, when the number of targets is  small, the PMHT will have a higher complexity than    A CRITICAL LOOK AT THE PMHT 103        TABLE I  Number of Combinations Considered by the JPDAF versus the    PMHT as a Function of the Number of Targets    M AJPDAF APMHT    1 n  t  +1 I    PN  t=2  n  t    2 n2  t  + n    t  +1 2I    PN  t=2  n  t    3 n3  t  +2n    t  +1 3I    PN  t=2  n  t    4 n4  t  ¡ 2n3    t  +5n2    t  +1 4I    PN  t=2  n  t    n  t  is the number of measurements in the frame considered,M is the    number of targets and I is the number of iterations that the PMHT  uses.    the JPDAF. Consistent with the simulation results of  Pao [46], practical implementations of the PMHT will  never have a lower complexity when there is only one  target. However, the complexity of the JPDAF scales  exponentially with the number of targets, whereas the  complexity of the PMHT scales linearly. So keeping the  batch length N fixed, the PMHT has a lower complexity  as the number of targets becomes large.    6. USING THE TRACKER OVER TIME    6.1. Growing and Sliding the Batch    The PMHT requires an initial estimate for all of  the states in the batch, as well as a the covariance of  the state estimate at the first time step. As empirically  demonstrated by Willett, Ruan, and Streit [70], a prac-  tical, efficient way of running the PMHT using a finite-  length batch is by growing and then sliding the batch.  In other words, at time t= 1 one is given the initial  state estimates of the targets xm(1). From time t= 2 to  time t=N, where N is the maximum batch-length, the  PMHT is run while increasing the batch length by one  each time. As mentioned in Section 4.1, in order to elim-  inate “data incest,” the state estimates at the beginning  of the batch should be removed from the estimation that  is not updated as part of the Kalman smoothing step.  The initial estimates of the states for the rest of the batch  are very important for convergence. Even with the use  of deterministic annealing, as described in Section 4.3,  if the initial state estimates for the batch are particularly  bad, then the EM algorithm probably will not converge  to the global maximum, nor to a nearby local maximum.  For that reason, the best initial state estimates are the  estimates from the previous time step. The best initial  state estimate for each target at the new step, which was  not estimated at the previous time step, is the the best  a priori estimate, which is the Kalman filter estimate  xm(t j t¡ 1).  At all time steps after the batch length has reached N,    the batch should slide one step forward, as demonstrated  in Fig. 1 by the Single Shift batch with respect to the  Pre-Shift Batch for a length N = 4 batch. In this case,  the previous estimate from the first time step becomes  the new initial state of the first step of the batch, which    Fig. 1. Different methods of shifting the window for the next time  step as shown on a length-4 batch. Each method has its own  concerns regarding the consistency of the estimator and the    avoidance of “data incest.”    must have an accurate covariance. Section 7 looks at  ways of estimating the covariance of this state estimate  as well as those of the other state estimates in the batch.    6.2. Other Methods of Sliding the Batch    It should be noted that the aforementioned method  of sliding the batch is somewhat ad-hoc. Much literature  has also focussed on sliding the batch over multiple time  steps at once, as shown with the Multishift Batch in  Fig. 1. If this approach is taken, one can not obtain  a real-time estimate of the target’s location, but must  wait until another batch of information has arrived.  Ruan, Willett, and Streit [52] suggested that the batches  should not overlap by more than one time step and  later suggested [70] that the initial state of the slid  batch, be it slid one step or many, be calculated using  only information equal to or prior to that time period.  For example, in the Single-Shift batch in Fig. 1, only  information from times 0 and 1 could be used to create  the initial state estimate at time 1. However, a length-one  PMHT is not a very good tracker. As a result, by using  this approach the initial estimates become progressively  worse.  The main concern regarding reusing smoothed past    state estimates is that it introduces “information incest”  in the smoothed state. However, it should be noted that  this concern only exists with the initial estimate at the  beginning of the batch. The rest of the initial estimates  in the batch affect to which local maximum the EM  algorithm is likely converge, but they do not affect the  location of the maxima in the likelihood function.  The new initial state when using a Single-Shift batch    from Fig. 1 and the smoothed state estimate from the  previous batch as the initial state, introduces information  incest in that it has already been smoothed from future  observations. In the Multi-Shift batch, where only a  single state overlaps, no information incest is present.  However, in the example of Fig. 1, the initial estimate  for time steps 4, 5, and 6 in the slid batch would have  to be Kalman filter predictions from the estimate at    104 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        time 3. If these are far from the true track location,  then it is likely that the precision errors will occur, as  described in Section 4.2 or that the EM algorithm is  likely to converge to a local maximum far from the  global maximum.  Thus, there is a tradeoff between how far one slides    the batch and how much “information incest” one  wishes to allow in the state estimate at the beginning of  the slid batch. Wieneke and Koch [66] decided to shift  a small number of steps, less than the batch length, and  use deterministic annealing. However, in many practical  situations, a state estimate is desired at every time step,  and thus the method of growing and sliding the batch  described in Section 6.1 is a simple approach.    7. COVARIANCE ESTIMATION IN THE PMHT    When sliding the batch, as described in the previous  section, an accurate covariance is needed for the new  estimate of the first time step of the batch. Additionally,  at any time during tracking, one may wish to have a co-  variance for the target state estimate. Being based upon  the EM algorithm, the PMHT does not directly provide  this. The simplest approximation is to use the covariance  estimates that are produced by the Kalman smoother at  each step. However, based upon the Normalized Esti-  mation Error Squared (NEES), which is more closely  defined in Setion 9, this has been shown to be inconsis-  tent.  In this section, we will look at two methods of    producing covariance estimations for the PMHT. One  approach, originally presented by Walsh [65], is to use  the inverse of the observed information to predict the  covariance. A simpler ad-hoc approach by Blanding,  Willett, Streit, and Dunham [6] is to obtain covariance  approximations by normalizing the posterior association  and using the covariance estimate from the JPDAF, (as  described, for example, in [3]).    7.1. Using the Observed Information to Estimate the  Covariance    Letting D be the dimensionality of the state, the  observed information matrix is defined as the DMN £  DMN Hessian of the joint likelihood function of the  states and observations over all time, evaluated at the  state estimate, in this case the EM estimate:    I[X̂,Z]  ¢  =¡r2X logp(Z,X)jX=X̂ (47)    = [¡r2X logp(X)¡r2X logp(Z jX)]jX=X̂  (48)    = Iprior[X̂] + Idata[Z j X̂]: (49)  The inverse of the observed information gives the co-  variance for all states over all time. The covariances of  the individual state estimates are in the D£D blocks  lying on the diagonal of the matrix.    Walsh is the first of have derived these Hessians for  the PMHT. We shall give a multisensor adaptation of  the observed information matrix as explained by [6],  assuming that all observations for a particular sensor at  a particular time have the same covariance and measure-  ment matrices. Iprior[X̂] is given as    Iprior[X̂] = diag  ··    Â(t) ¡±(t)  ¡±(t)0 Â(t+1)    ¸  : t= 1, : : : ,N ¡ 1    ¸  (50)    with    Â(t) =    8>>>>>>>>>>><  >>>>>>>>>>>:    diag[Pm(1 j 1)¡1 +Fm(1)0Qm(1)¡1Fm(1) :  m= 1, : : : ,M] for t= 1    diag[Q¡1m (t¡ 1)+Fm(t)0Q¡1m (t)Fm(t) :  m= 1, : : : ,M]    for t= 2, : : : ,T¡ 1  diag[Q¡1m (T¡ 1) :    m= 1, : : : ,M] for t= T    (51)and  ±(t) = diag[Fm(t)    0Qm(t)  ¡1 :    m= 1, : : : ,M] for t= 1, : : : ,T¡1:  (52)    Â(t) and ±(t) are MN £MN matrices. The contribution  from the data is given by    Idata[Z j X̂] =  NX  s=1    (B(s)¡C(s) +D(s)), (53)    B(s) = diag[B(t,s) : t= 1, : : : ,T], (54)    C(s) = diag[C(t,s) : t= 1, : : : ,T], (55)    D(s) = diag[D(t,s) : t= 1, : : : ,T], (56)    B(t,s) = diag[Hm,s(t)  0R̃m,s(t)    ¡1Hm,s(t) :    m= 1, : : : ,M], (57)    C(t,s) = diag    "  Hs(t)    0Rs(t)  ¡1    £  Ã  nt(s)X  r=1    wm,r(t,s)ºm,r(s, t)ºm,r(s, t)  0  !    £Rs(t)¡1Hs(t) : m= 1, : : : ,M  #  ,    (58)    D(t,s) =  nt(s)X  r=1    Dr(t,s)Dr(t,s)  0, (59)    and    Dr(t,s) =    2  664  wm,r(t,s)Hs(t)    0R¡11 (t)º1,r(t)    ...    wM,r(t,s)Hs(t)  0R¡1M (t)ºM,r(t)    3  775 : (60)    A CRITICAL LOOK AT THE PMHT 105        Note that B(t,s) contains the synthetic measurement co-  variance R̃m,s(t), whereas the other equations only con-  tain the covariance of the measurements. The innova-  tions are defined as follows:    ºm,r(s, t) =Hs(t)xm(t)¡ zr,s(t): (61)  The derivation of the observed information was per-  formed under the assumption that the transition matrix F  and the process noise covariance matrixQ are invertible.  This is true when using the discretized continuous white  noise acceleration model for the motion, but is not true  when using the discrete white noise acceleration model  [4], in which case a pseudoinverse would be necessary.8    7.2. A Simpler, Ad-hoc Approach to Covariance  Estimation    We shall extend the ad-hoc covariance estimation  approach taken by Blanding, Willett, Streit, and Dun-  ham [6] to the multisensor case. That is, we shall show  that estimator consistency is improved when the pos-  terior assignment probabilities are normalized and the  covariance estimate from the MSJPDAF is used. The  MSJPDAF is a generalization of the JPDAF to multiple  sensors (see, for example [3] for information on the ba-  sic JPDAF). There exist two forms of the MSJPDAF, a  sequential and a parallel one, which were contrasted by  Pao and Frei [45]. Because the sensor fusion is done in  parallel at each step of the PMHT, we shall consider the  parallel version of the MSJPDAF.  The MSJPDAF requires that the posterior associa-    tion probabilities sum to one over all measurements for  a particular target plus the probability that target was  not detected. This is because the MSJPDAF does not  make the same assumption as the PMHT, that each tar-  get can produce more than one measurement at a par-  ticular time. By noting that in the PMHT measurement  model the assignment of one measurement to the target  has no bearing on the probability that another measure-  ment is assigned to the same target, the probability that  a particular target m was not detected by a particular  sensor s at a particular time t is given as follows:    ¯m,0,s(t) =  ntY  r=1    (1¡wm,r(t,s)): (62)    Thus, the normalization over the observations, not  changing the probability of a missed detection is:    ¯m,r,s(t) = wm,r(t,s)  1¡¯m,0,s(t)Pnt  r=1wm,r(t,s)    : (63)    8The Moore-Penrose pseudoinverse of matrix A is A¡1 = (AA0)¡1A. If  AA0 is poorly conditioned, then the pseudoinverse can produce bad re-  sults. In simulations using the discrete white noise acceleration model,  we have observed that conditioning is often a problem in evaluating  the observed inverse of the information matrix.    The covariance update from the parallel MSJPDAF is:    Pm(t j t) =  ÃX    C  ¯m,C(t)(Pm,C(t j t) + xm,C(t j t)xm,C(t j t)0)    !  ¡ xm(t j t)xm(t j t)0: (64a)    Equation (64a) is the form given by Pao and Frei [45].  C represents a particular combination of assignments  between sensors for a particular target. Each ¯m,C is a  product of ¯m,r,s(t) terms over all sensors for a combi-  nation of assignments r, for each sensor. The whole set  of C is the set of all possible measurement to target and  clutter assignments at a particular time over all sensors.  This means that the covariance calculation is roughly  exponentially complex as a function of the number of  sensors.  In (64a), xm,C(t j t) represents the state update of the    Kalman filter if the measurement-assignment for all sen-  sors given by C is correct. This means fusing the actual  observations in the same way that the synthetic mea-  surements were fused in (29), (30), and (31) and then  updating the state estimate from the PMHT. By updat-  ing the PMHT state estimate reusing the observations,  a certain degree of “data incest” is added, but again this  method is ad-hoc and problems with the “incest” were  not observed in previous work using a single sensor [6].  The covariance Pm,C(t j t) is likewise what the covari-  ance would be if assignment C is correct. Since only the  first state of the PMHT has a covariance, the pre-update  covariance at time t would consist of Pm(t j t¡ 1), that  is the forward predicted covariance from the previous  estimate. In this manner, this covariance estimation al-  gorithm must be done in order from the first to the last  state estimate. xm(t j t) is a the weighted average of these  other state updates:    xm(t j t) =  X  C  ¯m,Cxm,C(t j t): (65)    8. A SUMMARY OF THE BASIC ALGORITHM    We shall give a summary of the basic PMHT algo-  rithm assuming that all targets have the same probability  of detection and that the measurements all have the same  measurement matrix H. If the detection probabilities are  different for all targets, then the prior and posterior as-  sociation probabilities referenced from the appendices  should be used. If the observations have different mea-  surement matrices, as might be the case if range-rate  information is available, then the alternative state update  equations given in Section 4 should be used.    1) Set the initial state estimate for each target at the  current time step to the Kalman filter predicted  value of the state xm(t j t¡ 1).    2) For each sensor and observation, calculate the pos-  terior assignment probabilities wkr,s(t),r(t,s) accord-  ing to (18) and (19).    106 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        3) Create the synthetic measurements z̃m,s(t) with their    corresponding measurement covariances R̃m,s(t) for  each target, measurement and sensor according to  (25) and (26) or (35) and (34).    4) Merge the synthetic measurements between sensors  according to (32) and (33).    5) Using the fixed initial state estimate xm(1) and state  covariance estimate Pm(1) for each track, run the  Kalman smoother, as described in Appendix D us-  ing the merged measurements as the observations.  Do not smooth the initial state.    6) Update the confusion matrix using (41).  7) Go to step 2. Repeat until convergence of the EM  algorithm.    8) If desired, estimate the covariance of the updated  state estimate xm(t j t) using a consistent approxima-  tion, such as (64a) or as described in Section 7.1.    9) Slide the batch window forward, using the proper  covariance estimate for the new initial state, such  as in (64a) or as described in Section 7.1.    10) Go to 1.    9. SIMULATION    We compared the consistency and track retention  rates of the MSJPDAF and the MSPMHT with and  without deterministic annealing and using the various  covariance estimation methods of Section 7 when us-  ing two sensors and two targets. The sequential ver-  sion of the MSJPDAF was used.9 We used the two-  dimensional discretized continuous white noise acceler-  ation model.10 Both sensors had the same field of view  and measured in Cartesian coordinates without classifi-  cation information. The ordering of the elements of the  state was [x,y, _x, _y]. Using an 80% probability of detect-  ing each track at each sensor, the simulation parameters  were    F=    2  6664  1 0 T 0    0 1 0 T    0 0 1 0    0 0 0 1    3  7775 , (66)    Q=    2  6664  T3=3 0 T2=2 0    0 T3=3 0 T2=2    T2=2 0 T 0    0 T2=2 0 T    3  7775¾2p, (67)    H=  ·  1 0 0 0    0 1 0 0    ¸  , (68)    9[47] discusses the sequential MSJPDAF algorithm, but provides an  incorrect state covariance estimate. [32] provides the correct state co-  variance estimate when solving a different problem.  10The one dimensional version is described in [4]; the two-dimension-  al version follows from it.    Fig. 2. A typical run of the simulation. The observations from the  first sensor and the last frame of clutter for that sensor are shown.    and    R=  ·  1 0    0 1    ¸  ¾2m: (69)    The sampling time T was set to 30 seconds. 1,000  Monte Carlo Runs were performed. The first target was  placed at the origin given an initial velocity of 7 m/s  at a 59± angle from the x axis. The second target was  assigned the same speed, and was placed at 500 m on  the y axis. Ascending at a 52± degree angle from the x  axis. ¾m was chosen to be 50 m for both sensors and ¾p  0:1 m2=s3. Clutter was generated uniformly in a view-  ing rectangle bounded between (¡200 m,¡200 m) and  (3:5 km,6 km). The number of clutter points was deter-  mined at each time step by a Poisson random variable  having mean 23. The MSPDAF was gated to observa-  tions within a 99.97 percent probability region around  the estimated location of the target. The simulation was  initialized by giving two correctly assigned measure-  ments for each track to information filters (the informa-  tion filter is described in [4]). For the PMHT, a window  growing to a maximum of length 10 was used. After  the 10th time step, the window slid. The PMHT was  performed using 10 iterations at each step.  Fig. 2 shows a typical run. The proportion of tracks    not lost at each step was calculated. A track was consid-  ered lost if at any point, the true location of the target  was outside of the 99.97 percent confidence interval of  the estimated target location. Fig. 3 shows the track-loss  performance. As expected, deterministic annealing sig-  nificantly improved the track-loss performance of the  MSPMHT.  To evaluate the consistency of the trackers, the av-    erage normalized estimation error squared (NEES) for  tracks that were not lost was calculated and averaged  over all tracks and Monte Carlo runs. The NEES is de-  fined as    NEES = (x(t)¡ x(t j t))P(t j t)¡1(x(t)¡ x(t j t))0:  (70)    A CRITICAL LOOK AT THE PMHT 107        Fig. 3. The fraction of tracks not lost at each step shown with and without the use of deterministic annealing. (a) Without DA. (b) With DA.    Fig. 4. The average NEES for tracks not lost by any of the trackers. The horizontal lines mark the 95 percent confidence interval of the  NEES. (a) Without DA. (b) With DA.    The NEES for a particular track is a random variable  with 4 degrees of freedom. The average NEES over  n Monte Carlo Runs is a chi-squared random variable  with 4n degrees of freedom. As mentioned in [4],  the inverse Cumulative Distribution Function (CDF)  of a chi-squared random variable given v degrees of  freedom, where v > 100, is approximately    X 2v (p)¼ 12  ³  G(p) +    p  2v¡ 1    ´2  : (71)    p is the probability at which the inverse CDF is to  be evaluated. G(p) is the inverse CDF of the standard  normal distribution. Thus for the 95 percent confidence  interval we get:    [G(0:025), G(0:975)] = [¡1:96, 1:96]: (72)  As can be seen in Fig. 4, the use of MSJPDAF    covariances in the two-sensor MSPMHT improves the  consistency of the tracker, even outperforming those ob-    tained by using the observed information approxima-  tions. However, as can be seen in Fig. 3, the use of  improved covariances has little effect on track reten-  tion. The apparent inconsistency of the initial estimate  in Fig. 4 stems from the fact that those tracks most often  lost by the PMHT were those where the covariance of  the initial estimate was underestimated. Deterministic  annealing significantly improves track retention. This  coincides with previous results done using a single sen-  sor on a single track [57] and [66].  All together, the MSPMHT performs worse than the    MSJPDAF in the two sensor scenario. However, the  poor performance of the basic PMHT has been shown  in previous literature and was one of the motivations  for the creation of other PMHT algorithms, such as the  MF-PMHT by Blanding, Willett, Streit, and Dunham  [7]. The multisensor PMHT presented in this paper can  form the basis of such modified algorithms.    108 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        10. CONCLUSION    We derived a general form of the PMHT involv-  ing clutter, multiple sensors, and classification measure-  ments. We provided a simpler method of performing  the maximization step when using multiple sensors. We  demonstrated that deterministic annealing can signif-  icantly improve tracker performance and we showed  that the JPDAF covariance approximations provide the  most consistent covariance estimates in the simulation,  but this consistency has little effect on the track reten-  tion as compared to using the synthetic covariances. We  also provided a simplified solution for the prior asso-  ciation probabilities (the ¼s). Although having worse  performance than comparable algorithms, such as the  MSPDAF, the PMHT algorithm derived here can form  the basis of other modifications of the PMHT, such as  the Turbo PMHT and the MFPMHT, which achieve bet-  ter track retention.    APPENDIX A. A DERIVATION OF THE POSTERIOR  ASSOCIATION PROBABILITIES wl,r(t,s)    The derivation of the posterior association proba-  bilities for the PMHT is dependent upon the sensor in  question. For simplicity, we shall assume that we are  only considering that which is seen by sensor s and  we shall suppress s from the notation. As has typically  been done, we shall derive it assuming that all sensors  see everything and that there is no gating.  In order to highlight the complexity reduction of the    PMHT measurement model, we shall begin by assum-  ing the regular target-measurement assignment model  (i.e., that a target can produce only one observation per  sensor at each time) before finishing the solution using  the PMHT measurement model. Let there be a total of  M non-clutter targets and one clutter target m= 0. Let  X(t) be the state of the Kalman filters for all non-clutter  targets at time t. Define zr(t) 2 Z(t) to be the rth mea-  surement out of the set of Z(t) measurements at time  t, which consists of nt measurements (in order to sim-  plify the notation, we shall omit the subscript on n).  zCr (t) shall be the classification value associated with  measurement zr(t). Define kr(t) to be source of the rth  measurement at time t.C shall be the set of all classifica-  tion probabilities c(i,m) = Pr(zCr (t) = i j kr(t) =m). The  classification of the target is assumed independent of  time and the target state. The probability that measure-  ment zr at time t came from target m given the current  set of observations, the set of classification probabili-  ties, and the estimated state of the set of Kalman filter  is wm,r(t) = Pr(kr(t) =m jX(t),Z(t),C,n). Using Bayes  Rule, this may be decomposed as follows:    w  m,r(t) =    Pr(Z(t) j k  r  (t) =m,X(t),C,n)Pr(k    r  (t) =m jX(t),C,n)PM    p=0  Pr(Z(t) j k    r  (t) = p,X(t),C,n)Pr(k    r  (t) = p j X(t),C,n)    (73a)    =  Pr(Z(t) j k    r  (t) =m,X(t),n)¼    m  (n)c(zC    r  ,m)PM    p=0  Pr(Z(t) j k    r  (t) = p,X(t),n)¼    tp  (n)c(zC    r  ,p)  : (73b)    Once we fix kr(t) =m, the probability of observing zr  is independent of the other track-measurement associ-  ations. Therefore, we may decompose Pr(Z(t) j kr(t) =  m,X(t),n) into two parts:    Pr(Z(t) j k  r  (t) =m,X(t),n)    = Pr(Z(t)nz  r  (t) jX(t)nx    m  (t),n) ¢Pr(z    r  (t) j k    r  (t) =m,x    m  (t),n):    (74)    Z(t)nzr(t) represents the set Z(t) without measurement  zr(t). X(t)nxm(t) represents the set X(t) without the el-  ements corresponding to track m. Let ft,m(q) be the  PDF of the estimated target location at time t for tar-  get m given X(t). If target m is not clutter, then this  is the Kalman filter estimate, which is normally dis-  tributed. This normal distribution comes directly from  the Kalman filter in (9) and has a covariance Rr(t) equal  to that associated with the measurement. If target m is  clutter, i.e., m= 0, then ft,0(q) is the PDF of the clutter  at point q. Usually this is assumed to be uniformly dis-  tributed over the field of view, but we shall designate it  by ¹(t,q) to allow for the use of a generic continuous  distribution to be used. We shall assume that ¹(t,q) is  continuous as a function of q. Hence we obtain    ft,m(q) =  ½  ¹(t,q) m= 0    N (q;HrX(t),Rr(t)) m 6= 0  : (75)    Because the PDFs of the measurements coming from  targets and those originating from clutter are assumed  continuous, Pr(zr j kr(t) =m,X(t),n) may be expressed  as the probability of the observation being within a  certain region around the observation as the size of  that region approaches zero. We shall denote the size  of this region as ¢ and the region itself, which is  centered about the observation zr as ¢(zr). Formulating  this probability as a limit allows us to deal with zeros  in the numerator and denominator of (74).    Pr(zr j kr(t) =m,X(t),n) = lim  ¢!0    Z  q2¢(zr)    ft,m(q)dq    (76)    = lim  ¢!0    ft,m(zr)¢: (77)    Substituting (77) and (74) into (73b) we get    w  m,r(t) = lim    ¢!0    Pr(Z(t)nz  r  (t) jX(t)nx    m  (t),n) ¢f    t,m(zr) ¢¢¼m(n) ¢ c(zCr ,m)PM  p=0    Pr(Z(t)nz  r  (t) jX(t)nx    p  (t),n)f    t,p(zr)¢¼p(n)c(z  C  r  ,p)    (78a)    =  Pr(Z(t)nz    r  (t) jX(t)nx    m  (t),n) ¢f    t,m(zr) ¢¼m(n) ¢ c(zCr ,m)PM  p=0    Pr(Z(t)nz  r  (t) j X(t)nx    p  (t),n)f    t,p(zt)¼p(n)c(z  C  r  ,p)  :    (78b)    The jump from (78a) to (78b) was accomplished by  noting that ¢ could be factored out of the sums and  products and thus cancels in the numerator and denom-  inator.    A CRITICAL LOOK AT THE PMHT 109        Equation (78b) is the solution assuming that each  target can produce only a single measurement. The  evaluation of Pr(Z(t)nzr(t) jX(t)nxm(t),n) is combinato-  rially complex. However, under the PMHT measure-  ment model, whereby a single target can produce any  number of measurements at one time, this becomes sim-  pler. Under the PMHT measurement model, (74) sim-  plifies as follows:    Pr(Z(t) j kr(t) =m,X(t),n)  = Pr(Z(t)nzr(t) jX(t),n) ¢Pr(zr(t) j kr(t) =m,xm(t),n):    (79)    This thus leaves a common term in (78b) that can be  cancelled, giving us:    wm,r(t) =  ft,m(zr)¼m(n)c(z    C  r ,m)PM    p=0ft,p(zt)¼p(n)c(z  C  r ,p)    : (80)    Substituting the appropriate distributions for ft,m(zr) and  ft,p(zt) gives us the form given in (17).    APPENDIX B. A DERIVATION OF THE PRIOR  ASSOCIATION PROBABILITIES  ¼m(nt(s), t)    B.1. A General Derivation of the Prior Association  Probabilities    Adopting the notation from the previous section, the  prior association probabilities are defined as    ¼m(n) = Pr(kr(t) =m jX(t),C,n): (81)  In this case, we are suppressing the conditioning on X(t)  and C in the notation of ¼, because, assuming that the  clutter is uniformly distributed in the viewing area, the  actual location of the target has no bearing on the so-  lution. In this section, we shall also suppress the condi-  tioning on time in order to simplify notation. We shall  derive the prior association probabilities assuming that  no gating is taking place and that all sensors have the  same field of view. It should be noted that the deriva-  tion of the ¼ values are the embodiment of the PMHT  measurement model. However, the PMHT measurement  model is only an approximation. For this purpose we  shall derive the ¼s based upon the usually more realis-  tic model that a single sensor can only observe at most  one measurement of each target at each time step.  The derivation of the ¼s takes place under the con-    straint that each measurement came either from a target  or from clutter, that is:    MX  m=0    ¼m(n) = 1: (82)    Thus, solving for the value of the non-clutter ¼ is  sufficient to tell us the value of the clutter ¼ for a  particular n. Let us now determine the values of ¼m(n)    given that m> 0. Using the Law of Total Probability to  perform a decomposition based upon the number no, of  targets observed we may thus write:    ¼m(n)  ¢  =Pr(kr =m j n) (83a)    =  min(n,M)X  k=1    Pr(kr =m j n, no = k)Pr(no = k j n):    (83b)    The Law of Total Probability may be used to sim-  plify the first term of (83b) by adding conditioning upon  whether observation zr originated from a target. The  first term of (83b) may be simplified as follows:    Pr(kr =m j n, no = k)  = Pr(kr =m j n, no = k, zr 2M)  £Pr(zr 2M j n, no = k): (84)    The second term in (84) can be found by counting:  if k targets are observed, then the probability that a  particular observation is a target is simply the ratio of  the number of targets observed to the total number of  observations. We thus have    Pr(zr 2M j n, no = k) =  k    n  : (85)    The first term of (84) may be decomposed using the  Law of Total Probability:    Pr(kr =m j n, no = k, zr 2M)  = Pr(kr =m j n, no = k, zr 2M, m observed)  £Pr(m observed j n, no = k, zr 2M) (86a)    =  μ  1  k    ¶  Pr(m observed j n, no = k, zr 2M):    (86b)    The notation “m observed” in the conditioning is an  abbreviation for “the mth target was observed.” The  jump from (86a) to (86b) was done by noting that if  we know that target m was observed, observation r  is a target and that k targets were observed, then by  counting, we know that the association probability is  1=k.  Let us define some additional notation. LetM be the    set of all measurements originating from a target, and pm  be the probability of detecting target m on a particular  scan. There shall be no p0 for clutter. We shall designate  the set of all pm as Pd. There are    ¡  M  k    ¢  ways of choosing    which k targets are observed for each item in the sum.  Let Pd(k) be the set of all products of k-combinations  from Pd without repetition. For example, if k = 2 and  M = 3, then Pd(2) = fp1p2, p1p3, p2p3g (the specific  ordering of the terms in not important). Define ek(y) to  be an enumerating function over Pk, giving us the yth  ordered element from Pd(k). Mk(y) shall represent the  set of k targets whose detection probabilities are part of    110 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        ek(y), i.e., it is a set of observed targets. Let ēk(y) be, if  k <M, the product of all M ¡ k elements of Pd that are  not used in ek(y), or ēk(y) = 1 if k =M. For example,  for k = 2 and M = 3, then e2(y) for y = 1 is p1p2, for  y = 2 is p1p3, and for y = 3 is p2p3. Likewise ē2(y) for  each y is respectively 1¡p3, 1¡p2, and 1¡p1. Let I(x)  be an indicator function that is 1 if x is nonzero.  Equation (86b) is equal to the sum of the probabili-    ties of all combinations of k observed targets such that  the mth target is observed:    Pr(m observed j n, no = k, zr 2M)    =    P(Mk )  y=1 ek(y)ēk(y)I(m 2Mk(y))P(Mk )    l=1 ek(l)ēk(l)  : (87)    Combining (87) with (86b) and (85) to form (84),  we get the following solution to the first term of (83b):    Pr(kr =m j n, no = k)    =    0  @P(Mk )y=1 ek(y)ēk(y)I(m 2Mk(y))P(Mk )    l=1 ek(l)ēk(l)    1  A 1  n  : (88)    The second term of (83b) may be simplified using  Bayes’ Theorem:    Pr(n0 = k j n) =  Pr(n j n0 = k)Pr(n0 = k)Pmin(n,M)    j=0 Pr(n j n0 = j)Pr(n0 = j)  :    (89)    Pr(n j n0 = k) from (89) is the probability that there are  n¡ k clutter points. We shall designate this probability  by the function »(n¡ k). Pr(n0 = k) from (89) is the  probability that k targets are observed and may be  written as follows:    Pr(n0 = k) =  (Mk )X  y=1    ek(y)ēk(y): (90)    Substituting (90) into (89), we get    Pr(n0 = k j n) =  »(n¡ k)    μP(Mk )  y=1 ek(y)ēk(y)    ¶  Pmin(n,M)    i=0 »(n¡ i)  μP(Mi )    y=1 ei(y)ēi(y)  ¶ :  (91)    Substituting (91) and (88) back into (83b), we get the  following expression for ¼m(n):    ¼  m  (n) =    8>>>>>>>><  >>>>>>>>:    1¡  MX  j=1    ¼  j  (n) m= 0    Pmin(n,M)  k=1 »(n¡ k)    P(Mk )  y=1 ek(y)ēk(y)I(m 2Mk(y))    n  Pmin(n,M)    i=0 »(n¡ i)  ³P(Mi )    y=1 ei(y)ēi(y)  ´  m 6= 0    :    (92)    B.2. Simplifying the Prior Association Probabilities    Typically, the detection probability of the targets is  unknown a priori. In this case, it is often simplest to  assume that all of the targets have the same detection  probability PD, which would be chosen based upon the  properties of the sensor and typical targets. When that  is the case, Pr(n0 = k) from (90) is the same as the  probability of having k successes out of M Bernoulli  trials each with a success probability of PD:    Pr(n0 = k) =  μ  M    k    ¶  PkD (1¡PD)M¡k: (93)    Additionally, Pr(m Observed j n, no = k, zr 2M)  from (86b) may easily be solved by counting. With M  targets total and k targets observed, the probability of  observing any particular target is just k=M. Hence we  obtain    Pr(m Observed j n, no = k, zr 2M) =  k    M  : (94)    Using these simplifications, ¼m(n) is the same for all  m 6= 0 and (92) may be written in the following simpli-  fied form:    ¼  m  (n) =    8><  >:  1¡M¼1(n) m= 0Pmin(n,M)    k=1 k»(n¡ k)  ¡  M  k    ¢  Pk  D  (1¡P    D  )M¡k    Mn  Pmin(n,M)    i=0 »(n¡ i)  ¡  M  i    ¢  PiD(1¡PD)M¡i    m 6= 0  :    (95)    The probability »(k) of observing k clutter points at  time t is often modeled as a Poisson probability mass  function with mean ¸V where ¸ represents the mean  amount of clutter per unit volume and V is the volume  of the viewing area. Thus, we have    »(k) =  (¸V)k    k!  e¡¸V: (96)    Substituting (96) into (95) for m 6= 0, we get    ¼  m  (n)j    m 6=0 =    Pmin(n,M)  k=1    k    (¸V)k(n¡ k)!  ¡  M  k    ¢  Pk  D  (1¡P    D  )M¡k    Mn  Pmin(n,M)    i=0    1  (¸V)i(n¡ i)!    ¡  M  i    ¢  PiD(1¡PD)M¡i    :    (97)    It can be noted that the ratio of consecutive terms of  the sums in the numerator and denominator of (97) are  ratios of polynomials in k. That is, the ratio of the ak+1  and the akth term of the sum in the numerator is    ak+1  ak    =  (k¡M)(k¡ n)    k    μ  PD    (1¡PD)¸V  ¶  : (98)    Likewise the ratio of the ak+1 and the akth term of the  sum in the denominator is    ak+1  ak    =  (k¡M)(k¡ n)  k(k+1)    μ  PD    (1¡PD)¸V  ¶  : (99)    A CRITICAL LOOK AT THE PMHT 111        TABLE II  Examples of ¼    m  (n)j    m 6=0 and ¼̄ when all Targets have the Same Detection Probability and a Poisson Clutter Model is Used    M ¼  m  (n)j    m 6=0 ¼̄    1  P  D    nP  D  +(1¡P    D  )¸V    μ  1  P  D    ¡ 1  ¶  + n¡ 1    2 P  2  D  (n¡ 1¡¸V) +P    D  ¸V    P2  D  n(n¡ 1)+2nP    D  ¸V(1¡P    D  )+ (1¡P    D  )2¸2V2    P  D  (n¡ 1)    P  D  (1¡ n+¸V)¡¸V +    μ  1  P  D    ¡ 1  ¶  + n¡ 1    Thus, following the method in [48], the sums may be  rewritten in terms of hypergeometric functions    ¼m(n) =    8>>>>><  >>>>>:    1¡M¼1(n) m= 0    ¡  2F0    ·  1¡M,1¡ n; PD    (1¡PD)¸V  ¸    2F0    ·  ¡M,¡n; PD    (1¡PD)¸V  ¸ m 6= 0 :    (100)    The function 2F0(a1,a2;z) in (100) is a hypergeometric  function.  Table II shows ¼m(n)jm 6=0 from (100) for one and    two targets. Previous publications, such as [3], have also  derived (100) for a single target under a Poisson clutter  model.    APPENDIX C. FURTHER SIMPLIFICATIONS TO THE  ws    If the probability of detection is the same for all  targets, then the ¼s and the ws may be simplified one  step further. Examining (95), it can be seen that all of the  ¼ values are the same for all targets. Using the simplified  form of the ws in equation (17), we can divide the ¼ term  from the numerator into the denominator to get    wkr,s(t),r(t,s) =  Nfzr,s(t); ŷkr,s(t)(t),Rr,s(t)gc(zCr,s(t),kr,s(t))    ¼̄(nt(s), t)¹(t,zr,s(t))c(z  C  r,s(t),0)+    PM  m=1Nfzr,s(t); ŷm(t),Rr,s(t)gc(zCr,s(t),m)    : (101)    This lowers the total number of multiplications needed  and it is more efficient to calculate ¼̄ than to calculate  the ¼ values for clutter and targets separately. When a  Poisson clutter model is used, as is the case in (100),  then, maintaining the notation from Section B, ¼̄ is given  as follows:    ¼̄ =  ¼0  ¼m 6=0    (102a)    =¡M ¡  2F0    ·  ¡M,¡n; PD    (1¡PD)¸V  ¸    2F0    ·  1¡M,1¡ n; PD    (1¡PD)¸V  ¸ :  (102b)    Some expressions for ¼̄ as a function of the number  of targets are given in Table II.    APPENDIX D. THE KALMAN SMOOTHER    In this section, we summarize the equations for the  Kalman smoother, as described in [4]. x(t1 j t2) repre-  sents the state estimate at time t1 given all observa-  tions from time 1 to t2, whereby x(0 j 0) is the initial  estimate. P(t1 j t2) is the covariance of the aforemen-  tioned state estimate. F(t) is the state transition matrix  and H(t) the measurement matrix, as shown in the dy-  namic equations in (8) and (9). In keeping with the dy-  namic model, Q(t) is the process noise covariance and  R(t) the measurement noise covariance, the noises be-  ing zero-mean and white. z(t) is the observation at time  t and R(t) is its covariance. The Kalman smoother con-  sists of a Kalman filtering step, after which a smooth-  ing step is applied. Letting I be the identity matrix,  the Kalman filter equations to calculate x(t j t) from  x(t¡ 1 j t¡ 1) and the observations at time t are given  by    x(t j t¡ 1) = F(t)x(t¡ 1 j t¡ 1), (103)    ŷ(t) =H(t)x(t j t¡ 1), (104)    P(t j t¡ 1) = F(t)P(t¡ 1 j t¡ 1)F(t)0+Q(t), (105)    W(t) = P(t j t¡ 1)H(t)0[R(t) +H(t)P(t j t¡ 1)H()0]¡1,  (106)    P(t j t) = [I¡W(t)H]P(t j t¡ 1)[I¡W(t)H(t)]0    +W(t)R(t)W(t), (107)    and  x(t j t) = x(t j t¡ 1)+W(t)[z(t)¡ ŷ(t)]: (108)    Assuming that there areN time-periods of data avail-  able, the smoothing is performed by starting with the  final estimate x(N jN) and going backwards along the  previous estimates, smoothing them using the following    112 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        equations    C(t) = P(t j t)F(t)0P(t+1 j t)¡1, (109)  x(t jN) = x(t j t)+C(t)[x(t+1 jN)¡ x(t+1 j t)],    (110)  and    P(t jN) = P(t j t) +C(t)[P(t+1 jN)¡P(t+1 j t)]C(t)0:  (111)    REFERENCES    [1] K. M. Alexiev  Multiple target tracking using Hough transform PMHT  algorithm.  In First International IEEE Symposium on “Intelligent Sys-  tems”, vol. 1, 2002, 227—232.    [2] D. Avitzour  A maximum likelihood approach to data association.  IEEE Transactions on Aerospace and Electronic Systems, 28,  2 (Apr. 1992), 560—566.    [3] Y. Bar-Shalom and X-R. Li  Multitarget-Multisensor Tracking: Principles and Techniques.  Storrs, CT: YBS Publishing, 1995.    [4] Y. Bar-Shalom, X-R. Li, and T. Kirubarajan  Estimation with Applications to Tracking and Navigation.  New York: John Wiley & Sons, 2001.    [5] D. P. Bertsekas  Nonlinear Programming (2nd ed.).  Belmont, MA.: Athena Scientific, 2003, 107—108.    [6] W. R. Blanding, P. Willett, R. L. Streit, and D. Dunham  Consistent covariance estimation for PMHT.  In Proceedings of SPIE: Signal and Data Processing of Small  Targets Conference, vol. 6699, San Diego, CA, Aug. 2007,  66 990I-1—66 990I-11.    [7] W. R. Blanding, P. Willett, R. L. Streit, and D. Dunham  Multi-frame assignment PMHT that accounts for missed  detections.  In Proceedings of the 10th International Conference on In-  formation Fusion, Quebec, Canada, July 2007.    [8] R. A. Boyles  On the convergence of the EM algorithm.  Journal of the Royal Statistical Society. Series B (Method-  ological), 45, 1 (1983), 47—50.    [9] S. J. Davey  Extensions to the probabilistic multi-hypothesis tracker for  improved data association.  Ph.D. dissertation, The University of Adelaide, Adelaide,  South Australia, Sept. 2003.    [10] S. J. Davey  Simultaneous localization and map building using the prob-  abilistic multi-hypothesis tracker.  IEEE Transactions on Robotics, 23, 2 (Apr. 2007), 271—280.    [11] S. J. Davey  Tracking possibly unresolved targets with PMHT.  In Information, Decision and Control, 2007, Feb. 2007, 47—  52.    [12] S. J. Davey and D. A. Gray  A comparison of track initiation methods with the PMHT.  In Information, Decision and Control, I.E.E.E. Press, Mar.  2002, this paper is found in the printed book; only a  conference schedule is on the IEEE’s web site.    [13] S. J. Davey and D. A. Gray  Integrated track maintenance for the PMHT via the hys-  teresis model.  IEEE Transactions on Aerospace and Electronic Systems, 37,  1 (Jan. 2007), 93—111.    [14] S. J. Davey, D. A. Gray, and R. L. Streit  Tracking, association, and classification: A combined  PMHT approach.  Digital Signal Processing, 12, 2—3 (2002), 372—382.    [15] S. J. Davey, M. G. Rutten, and B. Cheung  A comparison of detection performance for several track-  before detect algorithms.  EURASIP Journal on Advances in Signal Processing, 2008  (2008), article ID 428036.    [16] A. P. Dempster, N. M. Laird, and D. B. Rubin  Maximum likelihood from incomplete data via the EM  algorithm.  Journal of the Royal Statistical Society. Series B (Method-  ological), 39, 1 (1977), 1—38.    [17] D. T. Dunham and R. G. Hutchins  Hybrid tracking algorithm using MHT and PMHT.  In Proceedings of SPIE Conference: Signal and Data Pro-  cessing of Small Targets, vol. 4728, Orlando, FL, Apr. 2002,  166—175.    [18] M. Efe, Y. Ruan, and P. Willett  Probabilistic multi-hypothesis tracker-addressing some ba-  sic issues.  In IEEE Proceedings on Radar, Sonar and Navigation, vol.  151, no. 4, Aug. 2004, 189—196.    [19] M. Efe, Y. Ruan, and P. Willett  The pedestrian PMHT.  In Proceedings of the 5th International Conference on Infor-  mation Fusion, vol. 2, Annapolis, MD, 2002, 838—845.    [20] R. Frühwirth and A. Strandlie  Track fitting with ambiguities and noise: A study of elastic  tracking and non-linear filters.  Computer Physics Communications, 120, 2 (Aug. 1999),  197—214.    [21] Q. Gan and C. Harris  Comparison of two measurement fusion methods for Kal-  man-filter-based multisensor data fusion.  IEEE Transactions on Aerospace and Electronic Systems, 37,  1 (Jan. 2001), 273—279.    [22] H. Gauvrit, J. P. Le Cadre, and C. Jauffret  A formulation of multitarget tracking as an incomplete data  problem.  IEEE Transactions on Aerospace and Electronic Systems, 33,  4 (Oct. 1997), 1242—1257.    [23] E. Giannopoulos, R. L. Streit, and P. Swaszek  Multi-target track segment bearings-only association and  ranging.  In Conference Record of the Thirty-First Asilomar Confer-  ence on Signals, Systems & Computers, vol. 2, Pacific Grove,  CA, Nov. 1997, 1336—1340.    [24] E. Giannopoulos, R. L. Streit, and P. Swaszek  Probabilistic multi-hypothesis tracking in a multi-sensor  multi-target environment.  In ADFS ’96, First Australian Data Fusion Symposium,  Adelaide, SA, Australia, Nov. 1996, 184—189.    [25] K. Gilholm, S. Godsill, S. Maskell, and D. Salmond  Poisson models for extended target and group tracking.  In Proceedings of SPIE: Signal and Data Processing of Small  Targets Conference, vol. 5913, San Diego, CA, Aug. 2005,  59 130R-1—59 130R-12.    [26] C. G. Hempel  The effects of sensor registration error on the performance  of PMHT.  In Proceedings of the 11th International Conference on Infor-  mation Fusion, Cologne, Germany, June 2008, 1975—1979.    [27] C. Hue, J-P. Le Cadre, and P. Pérez  Tracking multiple objects with particle filtering.  IEEE Transactions on Aerospace and Electronic Systems, 38,  3 (July 2002), 791—812.    A CRITICAL LOOK AT THE PMHT 113        [28] C. Hue, J-P. Le Cadre, and P. Pérez  Sequential monte carlo methods for multiple target tracking  and data fusion.  IEEE Transactions on Signal Processing, 50, 2 (Feb. 2002),  309—325.    [29] R. G. Hutchins and D. T. Dunhan  Evaluation of a probabilistic multihypothesis tracking algo-  rithm in cluttered environments.  In Conference Record of the Thirtieth Asilomar Conference  on Signals, Systems and Computers, vol. 2, Nov. 1996,  1260—1264.    [30] C. F. Jeff Wu  On the convergence properties of the EM algorithm.  The Annals of Statistics, 11, 1 (1983), 95—103.    [31] H. Jeong and J-H. Park  An EM-based adaptive multiple target tracking filter.  International Journal of Adaptive Control and Signal Pro-  cessing, 16 (2002), 1—23.    [32] M. Kalandros and L. Y. Pao  Multisensor covariance control strategies for reducing bias  effects in interacting target scenarios.  IEEE Transactions on Aerospace and Electronic Systems, 41,  1 (Jan. 2005), 153—173.    [33] M. L. Krieg and D. A. Gray  Track fusion in the presence of an interference.  In Fourth International Symposium on Signal Processing and  Its Applications, 1996 (ISSPA ’96), vol. 1, Aug. 1996, 192—  195.    [34] A. Logothetis, V. Krishnamurthy, and J. Holst  On maneuvering target tracking via the PMHT.  In Proceedings of the 36th Conference on Decision and  Control, vol. 5, San Diego, CA, Dec. 1997, 5024—5029.    [35] A. Logothetis, V. Krishnamurthy, and J. Holst  A Bayesian EM algorithm for optimal tracking of a maneu-  vering target in clutter.  Signal Processing, 82, 3 (Mar. 2002), 473—490.    [36] Luginbuhl, P. Ainsleigh, S. Mathews, and R. L. Streit  Accurate likelihood evaluation for multiple model PMHT  algorithms.  In Aerospace Conference 2008, Mar. 2008.    [37] T. Luginbuhl and P. Willett  Tracking a general, frequency modulated signal in noise.  In Proceedings of the 38th Conference on and Control,  Phoenix, AZ, Dec. 1999.    [38] T. Luginbuhl and P. Willett  Estimating the parameters of general frequency modulated  signals.  IEEE Transactions on Signal Processing, 52, 1 (Jan. 2004),  117—131.    [39] T. Luginbuhl, Y. Sun, and P. Willett  A track management system for the PMHT algorithm.  In Proceedings of the 4th International Conference on Infor-  mation Fusion, Montreal, Canada, 2001.    [40] G. J. McLachlan and T. Krishnan  The EM Algorithm and Extensions.  New York: John Wiley & Sons, Inc., 1997.    [41] K. J. Molnar and J. W. Modestino  Application of the EM algorithm for the multitarget/multi-  sensor tracking problem.  IEEE Transactions on Signal Processing, 46, 1 (Jan. 1998),  115—129.    [42] T. Moon  The expectation-maximization algorithm.  IEEE Signal Processing Magazine, 13, 6 (Nov. 1996), 47—  60.    [43] D. Mu²sicki and X. Wang  Track management and PMHT.  In Proceedings of the 10th International Conference on In-  formation Fusion, Quebec, Canada, July 2007, 1—5.    [44] A. G. Pakfiliz and M. Efe  Multi-target tracking in clutter with histogram probabilistic  multi-hypothesis tracker.  In Proceedings of the IEEE 13th Signal Processing and  Communications Applications Conference, May 2005, 167—  168.    [45] L. Y. Pao and C. W. Frei  A comparison of parallel and sequential implementations  of a multisensor multitarget tracking algorithm.  In Proceedings of the American Control Conference, vol. 3,  Seattle, WA, June 1995, 1683—1687.    [46] L. Y. Pao and R. M. Powers  A comparison of several different approaches for target  tracking with clutter.  In Proceedings of the 2003 American Control Conference,  vol. 5, Denver, CO, June 2003, 3919—3924.    [47] L. Y. Pao and L. Trailović  The optimal order of processing sensor information in  sequential multisensor fusion algorithms.  IEEE Transactions on Automatic Control, 45, 8 (Aug. 2000),  1532—1536.    [48] M. Petkov²sek, H. S. Wilf, and D. Zeilberger  A= B.  Wellesley, MA: A K Peters, Ltd., 1996, ch. 3.    [49] G. W. Pulford and B. F. La Scala  MAP estimation of target maneuver sequence with the  expectation-maximization algorithm.  IEEE Transactions on Aerospace and Electronic Systems, 38,  2 (Apr. 2002), 367—377.    [50] G. Pulford and A. Logothetis  An expectation-maximisation tracker for multiple observa-  tions of a single target in clutter.  In Proceedings of the 36th IEEE Conference on Decision and  Control, vol. 5, Dec. 1997, 4997—5003.    [51] C. Rago, P. Willett, and R. L. Streit  Direct data fusion using the PMHT.  In Proceedings of the American Control Conference, vol. 3,  Seattle, WA, June 1995, 1698—1702.    [52] C. Rago, P. Willett, and R. L. Streit  A modified PMHT.  In Proceedings of the 1995 Conference on Information Sci-  ences and Systems, Mar. 2995.    [53] C. Rago, P. Willett, and R. Streit  A comparison of the JPDAF and PMHT tracking algo-  rithms.  In IEEE International Conference on Acoustics, Speech, and  Signal Processing (ICASSP-95), vol. 5, Detroit, MI, May  1995, 3571—3574.    [54] R. A. Redner and H. F. Walker  Mixture densities, maximum likelihood and the EM algo-  rithm.  SIAM Review, 26, 2 (Apr. 1984), 195—239.    [55] A. Roche  EM algorithm and variants: An informal tutorial.  CEA, Tech. Rep., 2003.    [56] Y. Ruan and P. Willett  The turbo PMHT.  IEEE Transactions on Aerospace and Electronic Systems, 40,  4 (Oct. 2004), 1388—1398.    [57] A. Strandlie and J. Zerubia  Particle tracking with iterated Kalman filters and smoothers:  the PMHT algorithm.  Computer Physics Communications, 123, 1 (Dec. 1999), 77—  86.    [58] R. L. Streit  Tracking on intensity-modulated data streams.  NUWC-NPT, Tech. Rep. 11,221, May 2000.    114 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009        [59] R. L. Streit  PMHT algorithms for multi-frame assignment.  In Proceedings of the 9th International Conference on Infor-  mation Fusion, Florence, Italy, July 2006.    [60] R. L. Streit and T. E. Luginbuhl  A probabilistic multi-hypothesis tracking algorithm without  enumeration and pruning.  In Proceedings of the Sixth Joint Service Data Fustion Sym-  posium, Laurel, Maryland, June 1993, 1015—1024.    [61] R. L. Streit and T. E. Luginbuhl  Probabilistic multi-hypothesis tracking.  NUWC-NPT, Tech. Rep. 10,428, Feb. 1995.    [62] N. Ueda and R. Nakano  Deterministic annealing EM algorithm.  Neural Networks, 11, 2 (Mar. 1998), 271—282.    [63] M. Verhaegen  Improved understanding of the loss-of-symmetry phenom-  enon in the conventional Kalman filter.  NASA, Tech. Rep. Technical Memorandum 100041, Dec.  1987.    [64] M. J. Walsh, M. L. Graham, R. L. Streit, T. Luginbuhl, and  L. Mathews  Tracking on intensity-modulated sensor data streams.  In Proceedings of the IEEE Aerospace Conference, vol. 4,  Big Sky, MT, 2001, 4/1901—4/1909.    [65] M. J. Walsh  Computing the observed information matrix for dynamic  mixture models.  NUWC-NPT, Tech. Rep. 11,768, Sept. 2006.    [66] M. Wieneke and W. Koch  The PMHT: Solutions for some of its problems.  In Proceedings of SPIE Conference: Signal and Data Pro-  cessing of Small Targets Conference, vol. 6699, San Diego,  CA, Aug. 2007, 1—12.    [67] M. Wieneke and W. Koch  On sequential track extraction within the PMHT frame-  work.  EURASIP Journal on Advances in Signal Processing, 2008  (2008), article ID 276914.    [68] M. Wieneke and P. Willett  On track-management within the PMHT framework.  In Proceedings of the 11th International Conference on In-  formation Fusion, Cologne, Germany, June 2008, 736—743.    [69] P. Willett, Y. Ruan, and R. Streit  The PMHT for maneuvering targets.  In Proceedings of SPIE: Signal and Data Processing of Small  Targets Conference, vol. 3373, Orlando, FL, Apr. 1998,  416—427.    [70] P. Willett, Y. Ruan, and R. L. Streit  A variety of PMHTs.  In Proceedings of the ISIS/PMHT Workshop, Paris, France,  Nov. 1998.    [71] P. Willett, Y. Ruan, and R. L. Streit  PMHT: Problems and some solutions.  IEEE Transactions on Aerospace and Electronic Systems, 38,  3 (July 2002), 738—754.    A CRITICAL LOOK AT THE PMHT 115        David F. Crouse (S’05) received the B.S. and M.S. degrees in electrical engineering, </p>
</div>
<div class="references">
<h2>References</h2>
<ul class="unstructured-references">
<li class="ref-1">K. M. Alexiev Multiple target tracking using Hough transform PMHT algorithm. In First International IEEE Symposium on “Intelligent Sys- tems”, vol. 1, 2002, 227—232.</li>
<li class="ref-2">A maximum likelihood approach to data association. IEEE Transactions on Aerospace and Electronic Systems, 28, 2 (Apr. 1992), 560—566.</li>
<li class="ref-3">Multitarget-Multisensor Tracking: Principles and Techniques. Storrs, CT: YBS Publishing, 1995.</li>
<li class="ref-4">Estimation with Applications to Tracking and Navigation. New York: John Wiley & Sons, 2001.</li>
<li class="ref-5">Nonlinear Programming (2nd ed.). Belmont, MA.: Athena Scientific, 2003, 107—108.</li>
<li class="ref-6">Consistent covariance estimation for PMHT. In Proceedings of SPIE: Signal and Data Processing of Small Targets Conference, vol. 6699, San Diego, CA, Aug. 2007, 66 990I-1—66 990I-11.</li>
<li class="ref-7">Multi-frame assignment PMHT that accounts for missed detections. In Proceedings of the 10th International Conference on In- formation Fusion, Quebec, Canada, July 2007.</li>
<li class="ref-8">On the convergence of the EM algorithm. Journal of the Royal Statistical Society. Series B (Method- ological), 45, 1 (1983), 47—50.</li>
<li class="ref-9">Extensions to the probabilistic multi-hypothesis tracker for improved data association. Ph.D. dissertation, The University of Adelaide, Adelaide, South Australia, Sept. 2003.</li>
<li class="ref-10">Simultaneous localization and map building using the prob- abilistic multi-hypothesis tracker. IEEE Transactions on Robotics, 23, 2 (Apr. 2007), 271—280.</li>
<li class="ref-11">Tracking possibly unresolved targets with PMHT. In Information, Decision and Control, 2007, Feb. 2007, 47— 52.</li>
<li class="ref-12">A comparison of track initiation methods with the PMHT. In Information, Decision and Control, I.E.E.E. Press, Mar. 2002, this paper is found in the printed book; only a conference schedule is on the IEEE’s web site.</li>
<li class="ref-13">Integrated track maintenance for the PMHT via the hys- teresis model. IEEE Transactions on Aerospace and Electronic Systems, 37, 1 (Jan. 2007), 93—111.</li>
<li class="ref-14">Tracking, association, and classification: A combined PMHT approach. Digital Signal Processing, 12, 2—3 (2002), 372—382.</li>
<li class="ref-15">A comparison of detection performance for several track- before detect algorithms. EURASIP Journal on Advances in Signal Processing, 2008 (2008), article ID 428036.</li>
<li class="ref-16">Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society. Series B (Method- ological), 39, 1 (1977), 1—38.</li>
<li class="ref-17">Hybrid tracking algorithm using MHT and PMHT. In Proceedings of SPIE Conference: Signal and Data Pro- cessing of Small Targets, vol. 4728, Orlando, FL, Apr. 2002, 166—175.</li>
<li class="ref-18">Probabilistic multi-hypothesis tracker-addressing some ba- sic issues. In IEEE Proceedings on Radar, Sonar and Navigation, vol. 151, no. 4, Aug. 2004, 189—196.</li>
<li class="ref-19">The pedestrian PMHT. In Proceedings of the 5th International Conference on Infor- mation Fusion, vol. 2, Annapolis, MD, 2002, 838—845.</li>
<li class="ref-20">Track fitting with ambiguities and noise: A study of elastic tracking and non-linear filters. Computer Physics Communications, 120, 2 (Aug. 1999), 197—214.</li>
<li class="ref-21">Comparison of two measurement fusion methods for Kal- man-filter-based multisensor data fusion. IEEE Transactions on Aerospace and Electronic Systems, 37, 1 (Jan. 2001), 273—279.</li>
<li class="ref-22">A formulation of multitarget tracking as an incomplete data problem. IEEE Transactions on Aerospace and Electronic Systems, 33, 4 (Oct. 1997), 1242—1257.</li>
<li class="ref-23">Multi-target track segment bearings-only association and ranging. In Conference Record of the Thirty-First Asilomar Confer- ence on Signals, Systems & Computers, vol. 2, Pacific Grove, CA, Nov. 1997, 1336—1340.</li>
<li class="ref-24">Probabilistic multi-hypothesis tracking in a multi-sensor multi-target environment. In ADFS ’96, First Australian Data Fusion Symposium, Adelaide, SA, Australia, Nov. 1996, 184—189.</li>
<li class="ref-25">Poisson models for extended target and group tracking. In Proceedings of SPIE: Signal and Data Processing of Small Targets Conference, vol. 5913, San Diego, CA, Aug. 2005, 59 130R-1—59 130R-12.</li>
<li class="ref-26">The effects of sensor registration error on the performance of PMHT. In Proceedings of the 11th International Conference on Infor- mation Fusion, Cologne, Germany, June 2008, 1975—1979.</li>
<li class="ref-27">Tracking multiple objects with particle filtering. IEEE Transactions on Aerospace and Electronic Systems, 38, 3 (July 2002), 791—812. A CRITICAL LOOK AT THE PMHT 113</li>
<li class="ref-28">Sequential monte carlo methods for multiple target tracking and data fusion. IEEE Transactions on Signal Processing, 50, 2 (Feb. 2002), 309—325.</li>
<li class="ref-29">Evaluation of a probabilistic multihypothesis tracking algo- rithm in cluttered environments. In Conference Record of the Thirtieth Asilomar Conference on Signals, Systems and Computers, vol. 2, Nov. 1996, 1260—1264.</li>
<li class="ref-30">On the convergence properties of the EM algorithm. The Annals of Statistics, 11, 1 (1983), 95—103.</li>
<li class="ref-31">An EM-based adaptive multiple target tracking filter. International Journal of Adaptive Control and Signal Pro- cessing, 16 (2002), 1—23.</li>
<li class="ref-32">Multisensor covariance control strategies for reducing bias effects in interacting target scenarios. IEEE Transactions on Aerospace and Electronic Systems, 41, 1 (Jan. 2005), 153—173.</li>
<li class="ref-33">Track fusion in the presence of an interference. In Fourth International Symposium on Signal Processing and Its Applications, 1996 (ISSPA ’96), vol. 1, Aug. 1996, 192— 195.</li>
<li class="ref-34">On maneuvering target tracking via the PMHT. In Proceedings of the 36th Conference on Decision and Control, vol. 5, San Diego, CA, Dec. 1997, 5024—5029.</li>
<li class="ref-35">A Bayesian EM algorithm for optimal tracking of a maneu- vering target in clutter. Signal Processing, 82, 3 (Mar. 2002), 473—490.</li>
<li class="ref-36">Accurate likelihood evaluation for multiple model PMHT algorithms. In Aerospace Conference 2008, Mar. 2008.</li>
<li class="ref-37">Tracking a general, frequency modulated signal in noise. In Proceedings of the 38th Conference on and Control, Phoenix, AZ, Dec. 1999.</li>
<li class="ref-38">Estimating the parameters of general frequency modulated signals. IEEE Transactions on Signal Processing, 52, 1 (Jan. 2004), 117—131.</li>
<li class="ref-39">A track management system for the PMHT algorithm. In Proceedings of the 4th International Conference on Infor- mation Fusion, Montreal, Canada, 2001.</li>
<li class="ref-40">The EM Algorithm and Extensions. New York: John Wiley & Sons, Inc., 1997.</li>
<li class="ref-41">Application of the EM algorithm for the multitarget/multi- sensor tracking problem. IEEE Transactions on Signal Processing, 46, 1 (Jan. 1998), 115—129.</li>
<li class="ref-42">The expectation-maximization algorithm. IEEE Signal Processing Magazine, 13, 6 (Nov. 1996), 47— 60.</li>
<li class="ref-43">Track management and PMHT. In Proceedings of the 10th International Conference on In- formation Fusion, Quebec, Canada, July 2007, 1—5.</li>
<li class="ref-44">Multi-target tracking in clutter with histogram probabilistic multi-hypothesis tracker. In Proceedings of the IEEE 13th Signal Processing and Communications Applications Conference, May 2005, 167— 168.</li>
<li class="ref-45">A comparison of parallel and sequential implementations of a multisensor multitarget tracking algorithm. In Proceedings of the American Control Conference, vol. 3, Seattle, WA, June 1995, 1683—1687.</li>
<li class="ref-46">A comparison of several different approaches for target tracking with clutter. In Proceedings of the 2003 American Control Conference, vol. 5, Denver, CO, June 2003, 3919—3924.</li>
<li class="ref-47">The optimal order of processing sensor information in sequential multisensor fusion algorithms. IEEE Transactions on Automatic Control, 45, 8 (Aug. 2000), 1532—1536.</li>
<li class="ref-48">A= B. Wellesley, MA: A K Peters, Ltd., 1996, ch. 3.</li>
<li class="ref-49">MAP estimation of target maneuver sequence with the expectation-maximization algorithm. IEEE Transactions on Aerospace and Electronic Systems, 38, 2 (Apr. 2002), 367—377.</li>
<li class="ref-50">An expectation-maximisation tracker for multiple observa- tions of a single target in clutter. In Proceedings of the 36th IEEE Conference on Decision and Control, vol. 5, Dec. 1997, 4997—5003.</li>
<li class="ref-51">Direct data fusion using the PMHT. In Proceedings of the American Control Conference, vol. 3, Seattle, WA, June 1995, 1698—1702.</li>
<li class="ref-52">A modified PMHT. In Proceedings of the 1995 Conference on Information Sci- ences and Systems, Mar. 2995.</li>
<li class="ref-53">A comparison of the JPDAF and PMHT tracking algo- rithms. In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP-95), vol. 5, Detroit, MI, May 1995, 3571—3574.</li>
<li class="ref-54">Mixture densities, maximum likelihood and the EM algo- rithm. SIAM Review, 26, 2 (Apr. 1984), 195—239.</li>
<li class="ref-55">EM algorithm and variants: An informal tutorial. CEA, Tech. Rep., 2003.</li>
<li class="ref-56">The turbo PMHT. IEEE Transactions on Aerospace and Electronic Systems, 40, 4 (Oct. 2004), 1388—1398.</li>
<li class="ref-57">Particle tracking with iterated Kalman filters and smoothers: the PMHT algorithm. Computer Physics Communications, 123, 1 (Dec. 1999), 77— 86.</li>
<li class="ref-58">Tracking on intensity-modulated data streams. NUWC-NPT, Tech. Rep. 11,221, May 2000. 114 JOURNAL OF ADVANCES IN INFORMATION FUSION VOL. 4, NO. 2 DECEMBER 2009</li>
<li class="ref-59">PMHT algorithms for multi-frame assignment. In Proceedings of the 9th International Conference on Infor- mation Fusion, Florence, Italy, July 2006.</li>
<li class="ref-60">A probabilistic multi-hypothesis tracking algorithm without enumeration and pruning. In Proceedings of the Sixth Joint Service Data Fustion Sym- posium, Laurel, Maryland, June 1993, 1015—1024.</li>
<li class="ref-61">Probabilistic multi-hypothesis tracking. NUWC-NPT, Tech. Rep. 10,428, Feb. 1995.</li>
<li class="ref-62">Deterministic annealing EM algorithm. Neural Networks, 11, 2 (Mar. 1998), 271—282.</li>
<li class="ref-63">Improved understanding of the loss-of-symmetry phenom- enon in the conventional Kalman filter. NASA, Tech. Rep. Technical Memorandum 100041, Dec. 1987.</li>
<li class="ref-64">L. Mathews Tracking on intensity-modulated sensor data streams. In Proceedings of the IEEE Aerospace Conference, vol. 4, Big Sky, MT, 2001, 4/1901—4/1909.</li>
<li class="ref-65">Computing the observed information matrix for dynamic mixture models. NUWC-NPT, Tech. Rep. 11,768, Sept. 2006.</li>
<li class="ref-66">The PMHT: Solutions for some of its problems. In Proceedings of SPIE Conference: Signal and Data Pro- cessing of Small Targets Conference, vol. 6699, San Diego, CA, Aug. 2007, 1—12.</li>
<li class="ref-67">On sequential track extraction within the PMHT frame- work. EURASIP Journal on Advances in Signal Processing, 2008 (2008), article ID 276914.</li>
<li class="ref-68">On track-management within the PMHT framework. In Proceedings of the 11th International Conference on In- formation Fusion, Cologne, Germany, June 2008, 736—743.</li>
<li class="ref-69">The PMHT for maneuvering targets. In Proceedings of SPIE: Signal and Data Processing of Small Targets Conference, vol. 3373, Orlando, FL, Apr. 1998, 416—427.</li>
<li class="ref-70">A variety of PMHTs. In Proceedings of the ISIS/PMHT Workshop, Paris, France, Nov. 1998.</li>
<li class="ref-71">PMHT: Problems and some solutions. IEEE Transactions on Aerospace and Electronic Systems, 38, 3 (July 2002), 738—754. A CRITICAL LOOK AT THE PMHT 115</li>
</ul>
</div>

</body>
</html>