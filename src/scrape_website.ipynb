{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import PyPDF2\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "from tika import parser\n",
    "from pathlib import Path\n",
    "from slugify import slugify\n",
    "from bs4 import BeautifulSoup\n",
    "from dicttoxml import dicttoxml\n",
    "from xml.dom.minidom import parseString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sgmcart3\\\\Documents\\\\Projects\\\\NLP\\\\isif_journal_pages'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://isif.org/journals/all\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_listing = soup.find(class_=\"view-isif-journals-listing\")\n",
    "journal_items = journal_listing.find_all(class_=\"field-name-field-journal-articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "depositor_name = \"\"\n",
    "depositor_email = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'find'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'get_text'\n",
      "'NoneType' object has no attribute 'find'\n"
     ]
    }
   ],
   "source": [
    "for journal_item in journal_items:\n",
    "    journal_url = journal_item.find(class_=\"field-name-field-journal-full-print\").find(\"a\", href=True)[\"href\"]\n",
    "\n",
    "    journal_page = requests.get(journal_url)\n",
    "    journal_soup = BeautifulSoup(journal_page.content, 'html.parser')\n",
    "\n",
    "    journal_date = journal_soup.find(class_=\"field-name-field-journal-date\").find(class_=\"field-items\").find(class_=\"date-display-single\").get_text()\n",
    "    journal_date_month = journal_date.split(\",\")[0]\n",
    "    journal_date_year = journal_date.split(\",\")[1].replace(\" \", \"\")\n",
    "    journal_vol_num = journal_soup.find(class_=\"field-name-field-journal-vol-num\").find(class_=\"field-items\").get_text()\n",
    "    journal_issue_num = journal_soup.find(class_=\"field-name-field-journal-issue-num\").find(class_=\"field-items\").get_text()\n",
    "    journal_issn = journal_soup.find(class_=\"field-name-field-journal-issn\").find(class_=\"field-items\").get_text()\n",
    "    journal_entries = journal_soup.find(class_=\"field-name-field-journal-entry-ref\").find(class_=\"field-items\").findChildren(class_=\"field-item\", recursive=False)\n",
    "\n",
    "    xml_output_dir = f\"{ROOT_DIR}/output/xml/{journal_vol_num}/{journal_issue_num}/\"\n",
    "    Path(xml_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    html_output_dir = f\"{ROOT_DIR}/output/html/{journal_vol_num}/{journal_issue_num}/\"\n",
    "    Path(html_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    paper_dir = f\"{ROOT_DIR}/data/papers/{journal_vol_num}/{journal_issue_num}/\"\n",
    "    preprocessed_paper_dir = f\"{ROOT_DIR}/data/preprocessed_papers/{journal_vol_num}/{journal_issue_num}/\"\n",
    "    meta_paper_dir = f\"{ROOT_DIR}/data/meta_papers/{journal_vol_num}/{journal_issue_num}/\"\n",
    "    Path(paper_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(preprocessed_paper_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(meta_paper_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    entries = {}\n",
    "    for journal_entry in journal_entries:\n",
    "        try:\n",
    "            entry_title = journal_entry.find(class_=\"field-name-field-journal-entry-file\").find(\"a\", href=True).get_text()\n",
    "            entry_pdf_url = journal_entry.find(class_=\"field-name-field-journal-entry-file\").find(\"a\", href=True)[\"href\"]\n",
    "            authors = journal_entry.find_all(class_=\"field-name-je-fc-author-displayname\")\n",
    "            entry_authors = [author.get_text() for author in authors]\n",
    "            entry_pages = journal_entry.find(class_=\"field-name-field-journal-entry-pages\").get_text()\n",
    "        \n",
    "            if os.path.exists(f\"{preprocessed_paper_dir}/{slugify(entry_title)}.pdf\") is False:\n",
    "                response = urllib.request.urlopen(entry_pdf_url)\n",
    "                file = open(f\"{paper_dir}/{slugify(entry_title)}.pdf\", 'wb')\n",
    "                file.write(response.read())\n",
    "                file.close()\n",
    "\n",
    "            if os.path.exists(f\"{preprocessed_paper_dir}/{slugify(entry_title)}.txt\") is False:\n",
    "                raw = parser.from_file(f\"{paper_dir}/{slugify(entry_title)}.pdf\")\n",
    "                content = str(raw[\"content\"])\n",
    "                meta = str(raw[\"metadata\"])\n",
    "                # h.update(content.encode('utf-8'))\n",
    "                # hashcode = h.hexdigest()\n",
    "                with open(f\"{preprocessed_paper_dir}/{slugify(entry_title)}.txt\", 'w', encoding='utf-8') as fid:\n",
    "                    fid.writelines(content)\n",
    "                with open(f\"{meta_paper_dir}/{slugify(entry_title)}.txt\", 'w', encoding='utf-8') as fid:\n",
    "                    fid.writelines(meta)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "#             print(journal_entry, \"\\n\\n\")\n",
    "            continue\n",
    "                    \n",
    "        extract_refs = False\n",
    "        recording_ref = False\n",
    "        references = {}\n",
    "        ref_count = 1\n",
    "        with open(f\"{preprocessed_paper_dir}/{slugify(entry_title)}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            ref_string = \"\"\n",
    "            for line in f:\n",
    "                if \"REFERENCES\" in line: extract_refs = True\n",
    "                if extract_refs:\n",
    "                    # Check for author name\n",
    "                    if any(\" \".join(author.split()) in line for author in entry_authors):\n",
    "                        references[ref_count] = ref_string\n",
    "                        ref_string = None\n",
    "                        break\n",
    "\n",
    "                    # Record references\n",
    "                    if (\"[\" in line) and (recording_ref is False):\n",
    "                        recording_ref = True\n",
    "                        ref_string = line.split(\"]\")[1]\n",
    "                        continue\n",
    "                    elif (\"[\" in line) and (recording_ref is True): # Start new ref\n",
    "                        references[ref_count] = ref_string\n",
    "                        ref_count += 1\n",
    "                        ref_string = \"\"\n",
    "                    elif recording_ref:\n",
    "                        ref_string += \" \" + line.replace(\"\\n\", \"\")\n",
    "            if ref_string is not None:\n",
    "                references[ref_count] = ref_string\n",
    "\n",
    "        entries[entry_title] = {\n",
    "            \"pdf_url\": entry_pdf_url,\n",
    "            \"authors\": entry_authors,\n",
    "            \"pages\": entry_pages,\n",
    "            \"references\": references,\n",
    "        }\n",
    "    \n",
    "    for entry_title in entries.keys():\n",
    "        # Write XML\n",
    "        with open(f\"{xml_output_dir}/{slugify(entry_title)}.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write('<doi_batch xmlns=\"http://www.crossref.org/schema/4.3.7\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" version=\"4.3.7\" xsi:schemaLocation=\"http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schema/deposit/crossref4.3.7.xsd\">\\n')\n",
    "\n",
    "            f.write(\"<head>\\n\")\n",
    "            f.write(f\"<doi_batch_id></doi_batch_id>\\n\")\n",
    "            f.write(f\"<timestamp>{time.time()}</timestamp>\\n\")\n",
    "            f.write(\"<depositor>\\n\")\n",
    "            f.write(f\"<depositor_name>{depositor_name}</depositor_name>\\n\")\n",
    "            f.write(f\"<email_address>{depositor_email}</email_address>\\n\")\n",
    "            f.write(\"</depositor>\\n\")\n",
    "            f.write(\"<registrant>WEB-FORM</registrant>\\n\")\n",
    "            f.write(\"</head>\\n\")  # End of Head\n",
    "\n",
    "            f.write(\"<body>\\n\")\n",
    "            f.write(\"<journal>\\n\")\n",
    "\n",
    "            f.write(\"<journal_metadata>\\n\")\n",
    "            f.write(\"<full_title>Journal of Advances in Information Fusion</full_title>\\n\")\n",
    "            f.write(\"<abbrev_title>JAIF</abbrev_title>\\n\")\n",
    "            f.write(f\"<issn media_type=\\\"print\\\">{journal_issn}</issn>\\n\")\n",
    "            f.write(\"</journal_metadata>\\n\")  # End journal metadata\n",
    "\n",
    "            f.write(\"<journal_issue>\\n\")\n",
    "            f.write(\"<publication_date media_type=\\\"print\\\">\\n\")\n",
    "            f.write(f\"<month>{journal_date_month}</month>\\n\")\n",
    "            f.write(f\"<day></day>\\n\")\n",
    "            f.write(f\"<year>{journal_date_year}</year>\\n\")\n",
    "            f.write(\"</publication_date>\\n\")\n",
    "\n",
    "            f.write(\"<journal_volume>\\n\")\n",
    "            f.write(f\"<volume>{journal_vol_num}</volume>\\n\")\n",
    "            f.write(\"</journal_volume>\\n\")\n",
    "            f.write(f\"<issue>{journal_issue_num}</issue>\\n\")\n",
    "            f.write(\"</journal_issue>\\n\")  # End journal issue\n",
    "\n",
    "            f.write(\"<journal_article publication_type=\\\"full_text\\\">\\n\")\n",
    "            f.write(\"<titles>\\n\")\n",
    "            f.write(f\"<title>{entry_title}</title>\\n\")\n",
    "            f.write(\"</titles>\\n\")\n",
    "            f.write(\"<contributors>\\n\")\n",
    "            for author in entries[entry_title][\"authors\"]:\n",
    "                names = author.split(\" \")\n",
    "                first_names = \" \".join(names[:-1])\n",
    "                last_name = names[-1]\n",
    "                f.write(\"<person_name sequence=\\\"first\\\" contributor_role=\\\"author\\\">\\n\")\n",
    "                f.write(f\"<given_name>{first_names}</given_name>\\n\")\n",
    "                f.write(f\"<surname>{last_name}</surname>\\n\")\n",
    "                f.write(f\"<ORCID></ORCID>\\n\")\n",
    "                f.write(\"</person_name>\\n\")\n",
    "            f.write(\"</contributors>\\n\")\n",
    "\n",
    "            f.write(\"<publication_date media_type=\\\"print\\\">\\n\")\n",
    "            f.write(f\"<month>{journal_date_month}</month>\\n\")\n",
    "            f.write(f\"<day></day>\\n\")\n",
    "            f.write(f\"<year>{journal_date_year}</year>\\n\")\n",
    "            f.write(\"</publication_date>\\n\")\n",
    "\n",
    "            pages = entries[entry_title][\"pages\"].replace(\"pg \", \"\").split(\"-\")\n",
    "\n",
    "            f.write(\"<pages>\\n\")\n",
    "            f.write(f\"<first_page>{pages[0]}</first_page>\\n\")\n",
    "            f.write(f\"<last_page>{pages[1]}</last_page>\\n\")\n",
    "            f.write(\"</pages>\\n\")\n",
    "\n",
    "            f.write(\"<citation_list>\\n\")\n",
    "            for ref_id in entries[entry_title][\"references\"].keys():\n",
    "                f.write(f'<citation key=\\\"ref-{ref_id}\">\\n')\n",
    "                f.write(f\"<unstructured_citation>{' '.join(entries[entry_title]['references'][ref_id].split())}</unstructured_citation>\\n\")\n",
    "                f.write(\"</citation>\\n\")\n",
    "            f.write(\"</citation_list>\\n\")\n",
    "            \n",
    "\n",
    "            f.write(\"</journal_article>\\n\")  # End journal article\n",
    "\n",
    "            f.write(\"</journal>\\n\")  # End of journal\n",
    "            f.write(\"</body>\\n\")  # End of body\n",
    "\n",
    "            f.write(f\"</doi_batch>\")  # End of XML\n",
    "    \n",
    "        # Write HTML\n",
    "        with open(f\"{html_output_dir}/{slugify(entry_title)}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            DOI = \"\"\n",
    "            f.write(\"<html>\\n\")\n",
    "            f.write(\"<body>\\n\")\n",
    "            f.write(\"<div class=\\\"article-parents\\\">\\n\")\n",
    "            f.write(\"<ul class=\\\"article-journal-name\\\">\\n\")\n",
    "            f.write(\"<li>Journal of Advances in Information Fusion (JAIF)</li>\\n\")\n",
    "            f.write(f\"<li>Volume {journal_vol_num}</li>\\n\")\n",
    "            f.write(f\"<li>Issue {journal_issue_num}</li>\\n\")\n",
    "            f.write(f\"<li>Pages {pages[0]} - {pages[1]}</li>\\n\")\n",
    "            f.write(f\"<li>{journal_date_month}, {journal_date_year}</li>\\n\")\n",
    "            f.write(f\"<li class=\\\"article-doi\\\"><a href=\\\"https://doi.org/{DOI}\\\">https://doi.org/{DOI}</a></li>\\n\")\n",
    "            f.write(\"</ul>\\n\")\n",
    "            f.write(\"</div>\\n\\n\")\n",
    "            \n",
    "            f.write(f\"<div class=\\\"article-header\\\">\\n\"),\n",
    "            f.write(f\"<h1 class=\\\"article-title\\\">{entry_title}</h1>\\n\")\n",
    "#             authors = \", \".join(entries[entry_title][\"authors\"])\n",
    "\n",
    "            if len(entries[entry_title][\"authors\"]) > 2:\n",
    "                authors = \", \".join(entries[entry_title][\"authors\"][:-1]) + \" and \" + str(entries[entry_title][\"authors\"][-1])\n",
    "            elif len(entries[entry_title][\"authors\"]) == 2:\n",
    "                authors = \" and \".join(entries[entry_title][\"authors\"])\n",
    "            elif len(entries[entry_title][\"authors\"]) == 1:\n",
    "                authors = entries[entry_title][\"authors\"][0]\n",
    "\n",
    "            f.write(f\"<p class=\\\"article-authors\\\">{authors}</p>\\n\")\n",
    "            f.write(f\"</div>\\n\\n\")\n",
    "\n",
    "            f.write(\"<div class=\\\"references\\\">\\n\")\n",
    "            f.write(\"<h2>References</h2>\\n\")\n",
    "            f.write(\"<ul class=\\\"unstructured-references\\\">\\n\")\n",
    "            for ref_id in entries[entry_title][\"references\"].keys():\n",
    "                f.write(f'<li class=\\\"ref-{ref_id}\">')\n",
    "                f.write(f\"{' '.join(entries[entry_title]['references'][ref_id].split())}\")\n",
    "                f.write(\"</li>\\n\")\n",
    "            f.write(\"</ul>\\n\")\n",
    "            f.write(\"</div>\\n\\n\")\n",
    "            \n",
    "            f.write(\"</body>\\n\")  # End of body\n",
    "            f.write(\"</html>\") # End of HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
